{
  "best_metric": 0.007847392000257969,
  "best_model_checkpoint": "./results\\checkpoint-4006",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 4006,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004992511233150275,
      "grad_norm": 3.4156993933720514e-05,
      "learning_rate": 5.726539784083926e-05,
      "loss": 0.0,
      "step": 10
    },
    {
      "epoch": 0.00998502246630055,
      "grad_norm": 3.589507832657546e-05,
      "learning_rate": 5.716993960139795e-05,
      "loss": 0.0,
      "step": 20
    },
    {
      "epoch": 0.014977533699450823,
      "grad_norm": 7.3673327278811485e-06,
      "learning_rate": 5.707448136195665e-05,
      "loss": 0.0,
      "step": 30
    },
    {
      "epoch": 0.0199700449326011,
      "grad_norm": 9.728026270749979e-06,
      "learning_rate": 5.697902312251534e-05,
      "loss": 0.0,
      "step": 40
    },
    {
      "epoch": 0.02496255616575137,
      "grad_norm": 4.1115695239568595e-06,
      "learning_rate": 5.688356488307404e-05,
      "loss": 0.0,
      "step": 50
    },
    {
      "epoch": 0.029955067398901646,
      "grad_norm": 3.733493940671906e-06,
      "learning_rate": 5.678810664363273e-05,
      "loss": 0.0,
      "step": 60
    },
    {
      "epoch": 0.034947578632051925,
      "grad_norm": 6.106925138738006e-05,
      "learning_rate": 5.669264840419142e-05,
      "loss": 0.1664,
      "step": 70
    },
    {
      "epoch": 0.0399400898652022,
      "grad_norm": 0.0011504451977089047,
      "learning_rate": 5.659719016475012e-05,
      "loss": 0.1053,
      "step": 80
    },
    {
      "epoch": 0.044932601098352475,
      "grad_norm": 0.06585656851530075,
      "learning_rate": 5.650173192530881e-05,
      "loss": 0.1726,
      "step": 90
    },
    {
      "epoch": 0.04992511233150274,
      "grad_norm": 0.021707838401198387,
      "learning_rate": 5.640627368586751e-05,
      "loss": 0.0001,
      "step": 100
    },
    {
      "epoch": 0.05491762356465302,
      "grad_norm": 0.0005782552761957049,
      "learning_rate": 5.6310815446426205e-05,
      "loss": 0.001,
      "step": 110
    },
    {
      "epoch": 0.05991013479780329,
      "grad_norm": 0.001781991682946682,
      "learning_rate": 5.6215357206984894e-05,
      "loss": 0.0,
      "step": 120
    },
    {
      "epoch": 0.06490264603095357,
      "grad_norm": 0.0003231308946851641,
      "learning_rate": 5.611989896754359e-05,
      "loss": 0.0,
      "step": 130
    },
    {
      "epoch": 0.06989515726410385,
      "grad_norm": 0.0003042332245968282,
      "learning_rate": 5.602444072810228e-05,
      "loss": 0.0,
      "step": 140
    },
    {
      "epoch": 0.07488766849725412,
      "grad_norm": 8.8368498836644e-05,
      "learning_rate": 5.592898248866098e-05,
      "loss": 0.0,
      "step": 150
    },
    {
      "epoch": 0.0798801797304044,
      "grad_norm": 0.00022151897428557277,
      "learning_rate": 5.583352424921968e-05,
      "loss": 0.0,
      "step": 160
    },
    {
      "epoch": 0.08487269096355467,
      "grad_norm": 0.0003082979819737375,
      "learning_rate": 5.5738066009778366e-05,
      "loss": 0.0,
      "step": 170
    },
    {
      "epoch": 0.08986520219670495,
      "grad_norm": 0.0001316075649810955,
      "learning_rate": 5.564260777033706e-05,
      "loss": 0.0,
      "step": 180
    },
    {
      "epoch": 0.09485771342985522,
      "grad_norm": 0.00027255737222731113,
      "learning_rate": 5.554714953089575e-05,
      "loss": 0.0,
      "step": 190
    },
    {
      "epoch": 0.09985022466300549,
      "grad_norm": 0.00026007447740994394,
      "learning_rate": 5.5451691291454454e-05,
      "loss": 0.0,
      "step": 200
    },
    {
      "epoch": 0.10484273589615577,
      "grad_norm": 0.00011854161130031571,
      "learning_rate": 5.535623305201315e-05,
      "loss": 0.0,
      "step": 210
    },
    {
      "epoch": 0.10983524712930604,
      "grad_norm": 0.0003807540924753994,
      "learning_rate": 5.526077481257184e-05,
      "loss": 0.0,
      "step": 220
    },
    {
      "epoch": 0.11482775836245632,
      "grad_norm": 9.115180728258565e-05,
      "learning_rate": 5.5165316573130535e-05,
      "loss": 0.0,
      "step": 230
    },
    {
      "epoch": 0.11982026959560658,
      "grad_norm": 6.165377999423072e-05,
      "learning_rate": 5.506985833368923e-05,
      "loss": 0.0,
      "step": 240
    },
    {
      "epoch": 0.12481278082875687,
      "grad_norm": 7.368786464212462e-05,
      "learning_rate": 5.497440009424792e-05,
      "loss": 0.0,
      "step": 250
    },
    {
      "epoch": 0.12980529206190713,
      "grad_norm": 0.00021892697259318084,
      "learning_rate": 5.487894185480662e-05,
      "loss": 0.0,
      "step": 260
    },
    {
      "epoch": 0.13479780329505742,
      "grad_norm": 0.00012781105760950595,
      "learning_rate": 5.478348361536531e-05,
      "loss": 0.0,
      "step": 270
    },
    {
      "epoch": 0.1397903145282077,
      "grad_norm": 9.230784053215757e-05,
      "learning_rate": 5.468802537592401e-05,
      "loss": 0.0,
      "step": 280
    },
    {
      "epoch": 0.14478282576135795,
      "grad_norm": 4.532918319455348e-05,
      "learning_rate": 5.45925671364827e-05,
      "loss": 0.0,
      "step": 290
    },
    {
      "epoch": 0.14977533699450823,
      "grad_norm": 2.198884976678528e-05,
      "learning_rate": 5.449710889704139e-05,
      "loss": 0.0,
      "step": 300
    },
    {
      "epoch": 0.15476784822765852,
      "grad_norm": 0.00014154499513097107,
      "learning_rate": 5.440165065760009e-05,
      "loss": 0.0,
      "step": 310
    },
    {
      "epoch": 0.1597603594608088,
      "grad_norm": 0.00016192218754440546,
      "learning_rate": 5.4306192418158784e-05,
      "loss": 0.0,
      "step": 320
    },
    {
      "epoch": 0.16475287069395905,
      "grad_norm": 6.30784998065792e-05,
      "learning_rate": 5.421073417871748e-05,
      "loss": 0.0,
      "step": 330
    },
    {
      "epoch": 0.16974538192710933,
      "grad_norm": 0.00014552600623574108,
      "learning_rate": 5.4115275939276175e-05,
      "loss": 0.0,
      "step": 340
    },
    {
      "epoch": 0.17473789316025962,
      "grad_norm": 4.588506635627709e-05,
      "learning_rate": 5.4019817699834864e-05,
      "loss": 0.0,
      "step": 350
    },
    {
      "epoch": 0.1797304043934099,
      "grad_norm": 5.022474942961708e-05,
      "learning_rate": 5.392435946039356e-05,
      "loss": 0.0,
      "step": 360
    },
    {
      "epoch": 0.18472291562656015,
      "grad_norm": 8.401740342378616e-05,
      "learning_rate": 5.3828901220952256e-05,
      "loss": 0.0,
      "step": 370
    },
    {
      "epoch": 0.18971542685971043,
      "grad_norm": 0.0001780950406100601,
      "learning_rate": 5.373344298151095e-05,
      "loss": 0.0,
      "step": 380
    },
    {
      "epoch": 0.19470793809286072,
      "grad_norm": 5.16545660502743e-05,
      "learning_rate": 5.363798474206965e-05,
      "loss": 0.0,
      "step": 390
    },
    {
      "epoch": 0.19970044932601097,
      "grad_norm": 2.650930400704965e-05,
      "learning_rate": 5.354252650262834e-05,
      "loss": 0.0,
      "step": 400
    },
    {
      "epoch": 0.20469296055916125,
      "grad_norm": 6.13796291872859e-05,
      "learning_rate": 5.344706826318703e-05,
      "loss": 0.0,
      "step": 410
    },
    {
      "epoch": 0.20968547179231153,
      "grad_norm": 0.00010375602869316936,
      "learning_rate": 5.335161002374572e-05,
      "loss": 0.0,
      "step": 420
    },
    {
      "epoch": 0.21467798302546182,
      "grad_norm": 1.1045178325730376e-05,
      "learning_rate": 5.3256151784304424e-05,
      "loss": 0.0,
      "step": 430
    },
    {
      "epoch": 0.21967049425861207,
      "grad_norm": 8.779280324233696e-05,
      "learning_rate": 5.316069354486312e-05,
      "loss": 0.0,
      "step": 440
    },
    {
      "epoch": 0.22466300549176235,
      "grad_norm": 5.428400618257001e-05,
      "learning_rate": 5.306523530542181e-05,
      "loss": 0.0,
      "step": 450
    },
    {
      "epoch": 0.22965551672491263,
      "grad_norm": 4.437097595655359e-05,
      "learning_rate": 5.2969777065980505e-05,
      "loss": 0.0,
      "step": 460
    },
    {
      "epoch": 0.23464802795806292,
      "grad_norm": 0.0001245718012796715,
      "learning_rate": 5.2874318826539194e-05,
      "loss": 0.0,
      "step": 470
    },
    {
      "epoch": 0.23964053919121317,
      "grad_norm": 7.497344631701708e-05,
      "learning_rate": 5.277886058709789e-05,
      "loss": 0.0,
      "step": 480
    },
    {
      "epoch": 0.24463305042436345,
      "grad_norm": 7.293189992196858e-05,
      "learning_rate": 5.268340234765659e-05,
      "loss": 0.0,
      "step": 490
    },
    {
      "epoch": 0.24962556165751373,
      "grad_norm": 0.00011279990576440468,
      "learning_rate": 5.258794410821528e-05,
      "loss": 0.0,
      "step": 500
    },
    {
      "epoch": 0.254618072890664,
      "grad_norm": 3.1214425689540803e-05,
      "learning_rate": 5.249248586877398e-05,
      "loss": 0.0,
      "step": 510
    },
    {
      "epoch": 0.25961058412381427,
      "grad_norm": 6.904877227498218e-05,
      "learning_rate": 5.2397027629332666e-05,
      "loss": 0.0,
      "step": 520
    },
    {
      "epoch": 0.2646030953569646,
      "grad_norm": 5.263775528874248e-05,
      "learning_rate": 5.230156938989136e-05,
      "loss": 0.0,
      "step": 530
    },
    {
      "epoch": 0.26959560659011483,
      "grad_norm": 5.928717291681096e-05,
      "learning_rate": 5.220611115045006e-05,
      "loss": 0.0,
      "step": 540
    },
    {
      "epoch": 0.2745881178232651,
      "grad_norm": 2.0573575966409408e-05,
      "learning_rate": 5.2110652911008754e-05,
      "loss": 0.0,
      "step": 550
    },
    {
      "epoch": 0.2795806290564154,
      "grad_norm": 3.1140145438257605e-05,
      "learning_rate": 5.201519467156745e-05,
      "loss": 0.0003,
      "step": 560
    },
    {
      "epoch": 0.28457314028956565,
      "grad_norm": 2.7768357540480793e-05,
      "learning_rate": 5.191973643212614e-05,
      "loss": 0.0,
      "step": 570
    },
    {
      "epoch": 0.2895656515227159,
      "grad_norm": 3.656021726783365e-05,
      "learning_rate": 5.1824278192684835e-05,
      "loss": 0.0,
      "step": 580
    },
    {
      "epoch": 0.2945581627558662,
      "grad_norm": 2.6687996069085784e-05,
      "learning_rate": 5.172881995324353e-05,
      "loss": 0.0,
      "step": 590
    },
    {
      "epoch": 0.29955067398901647,
      "grad_norm": 0.0011652617249637842,
      "learning_rate": 5.1633361713802226e-05,
      "loss": 0.1246,
      "step": 600
    },
    {
      "epoch": 0.3045431852221667,
      "grad_norm": 0.0025253857020288706,
      "learning_rate": 5.153790347436092e-05,
      "loss": 0.1533,
      "step": 610
    },
    {
      "epoch": 0.30953569645531703,
      "grad_norm": 0.0002855365164577961,
      "learning_rate": 5.144244523491962e-05,
      "loss": 0.0009,
      "step": 620
    },
    {
      "epoch": 0.3145282076884673,
      "grad_norm": 0.0017147090984508395,
      "learning_rate": 5.134698699547831e-05,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.3195207189216176,
      "grad_norm": 0.12737888097763062,
      "learning_rate": 5.1251528756037e-05,
      "loss": 0.0,
      "step": 640
    },
    {
      "epoch": 0.32451323015476785,
      "grad_norm": 0.0004102980892639607,
      "learning_rate": 5.115607051659569e-05,
      "loss": 0.0,
      "step": 650
    },
    {
      "epoch": 0.3295057413879181,
      "grad_norm": 0.000531757075805217,
      "learning_rate": 5.1060612277154394e-05,
      "loss": 0.0,
      "step": 660
    },
    {
      "epoch": 0.3344982526210684,
      "grad_norm": 0.0009127967641688883,
      "learning_rate": 5.096515403771309e-05,
      "loss": 0.0,
      "step": 670
    },
    {
      "epoch": 0.33949076385421867,
      "grad_norm": 0.0003115274594165385,
      "learning_rate": 5.086969579827178e-05,
      "loss": 0.0,
      "step": 680
    },
    {
      "epoch": 0.3444832750873689,
      "grad_norm": 0.00038755303830839694,
      "learning_rate": 5.0774237558830475e-05,
      "loss": 0.0,
      "step": 690
    },
    {
      "epoch": 0.34947578632051923,
      "grad_norm": 0.0002707921084947884,
      "learning_rate": 5.0678779319389164e-05,
      "loss": 0.0316,
      "step": 700
    },
    {
      "epoch": 0.3544682975536695,
      "grad_norm": 0.0008451403700746596,
      "learning_rate": 5.058332107994786e-05,
      "loss": 0.0,
      "step": 710
    },
    {
      "epoch": 0.3594608087868198,
      "grad_norm": 0.0013484139926731586,
      "learning_rate": 5.048786284050656e-05,
      "loss": 0.0,
      "step": 720
    },
    {
      "epoch": 0.36445332001997005,
      "grad_norm": 0.0003909412189386785,
      "learning_rate": 5.039240460106525e-05,
      "loss": 0.0,
      "step": 730
    },
    {
      "epoch": 0.3694458312531203,
      "grad_norm": 0.0009275181218981743,
      "learning_rate": 5.029694636162395e-05,
      "loss": 0.2445,
      "step": 740
    },
    {
      "epoch": 0.3744383424862706,
      "grad_norm": 104.48899841308594,
      "learning_rate": 5.020148812218264e-05,
      "loss": 0.332,
      "step": 750
    },
    {
      "epoch": 0.37943085371942087,
      "grad_norm": 0.0004958486533723772,
      "learning_rate": 5.010602988274133e-05,
      "loss": 0.1406,
      "step": 760
    },
    {
      "epoch": 0.3844233649525711,
      "grad_norm": 16.293922424316406,
      "learning_rate": 5.0010571643300035e-05,
      "loss": 0.142,
      "step": 770
    },
    {
      "epoch": 0.38941587618572143,
      "grad_norm": 0.012889736331999302,
      "learning_rate": 4.9915113403858724e-05,
      "loss": 0.1199,
      "step": 780
    },
    {
      "epoch": 0.3944083874188717,
      "grad_norm": 0.038806475698947906,
      "learning_rate": 4.981965516441742e-05,
      "loss": 0.0927,
      "step": 790
    },
    {
      "epoch": 0.39940089865202194,
      "grad_norm": 0.004238388035446405,
      "learning_rate": 4.972419692497611e-05,
      "loss": 0.0621,
      "step": 800
    },
    {
      "epoch": 0.40439340988517225,
      "grad_norm": 0.004416682291775942,
      "learning_rate": 4.9628738685534805e-05,
      "loss": 0.0015,
      "step": 810
    },
    {
      "epoch": 0.4093859211183225,
      "grad_norm": 145.69378662109375,
      "learning_rate": 4.95332804460935e-05,
      "loss": 0.27,
      "step": 820
    },
    {
      "epoch": 0.4143784323514728,
      "grad_norm": 0.02480713091790676,
      "learning_rate": 4.9437822206652197e-05,
      "loss": 0.1379,
      "step": 830
    },
    {
      "epoch": 0.41937094358462307,
      "grad_norm": 0.012086103670299053,
      "learning_rate": 4.934236396721089e-05,
      "loss": 0.0009,
      "step": 840
    },
    {
      "epoch": 0.4243634548177733,
      "grad_norm": 0.02029472403228283,
      "learning_rate": 4.924690572776958e-05,
      "loss": 0.0008,
      "step": 850
    },
    {
      "epoch": 0.42935596605092363,
      "grad_norm": 0.007145610637962818,
      "learning_rate": 4.915144748832828e-05,
      "loss": 0.0001,
      "step": 860
    },
    {
      "epoch": 0.4343484772840739,
      "grad_norm": 0.001243840204551816,
      "learning_rate": 4.905598924888697e-05,
      "loss": 0.0001,
      "step": 870
    },
    {
      "epoch": 0.43934098851722414,
      "grad_norm": 0.002050847513601184,
      "learning_rate": 4.896053100944566e-05,
      "loss": 0.0684,
      "step": 880
    },
    {
      "epoch": 0.44433349975037445,
      "grad_norm": 0.001442120410501957,
      "learning_rate": 4.8865072770004365e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.4493260109835247,
      "grad_norm": 0.0020642210729420185,
      "learning_rate": 4.8769614530563054e-05,
      "loss": 0.1049,
      "step": 900
    },
    {
      "epoch": 0.454318522216675,
      "grad_norm": 0.0028603975661098957,
      "learning_rate": 4.867415629112175e-05,
      "loss": 0.0,
      "step": 910
    },
    {
      "epoch": 0.45931103344982527,
      "grad_norm": 0.0011391950538381934,
      "learning_rate": 4.8578698051680446e-05,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 0.4643035446829755,
      "grad_norm": 0.0005182134918868542,
      "learning_rate": 4.8483239812239135e-05,
      "loss": 0.0,
      "step": 930
    },
    {
      "epoch": 0.46929605591612583,
      "grad_norm": 0.0011997140245512128,
      "learning_rate": 4.838778157279784e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.4742885671492761,
      "grad_norm": 0.0017071517650038004,
      "learning_rate": 4.8292323333356526e-05,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 0.47928107838242634,
      "grad_norm": 0.0010583337862044573,
      "learning_rate": 4.819686509391522e-05,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 0.48427358961557665,
      "grad_norm": 0.0009224255918525159,
      "learning_rate": 4.810140685447392e-05,
      "loss": 0.0,
      "step": 970
    },
    {
      "epoch": 0.4892661008487269,
      "grad_norm": 0.0007530600996688008,
      "learning_rate": 4.800594861503261e-05,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 0.49425861208187716,
      "grad_norm": 0.00030461023561656475,
      "learning_rate": 4.79104903755913e-05,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 0.49925112331502747,
      "grad_norm": 0.04060198366641998,
      "learning_rate": 4.7815032136150005e-05,
      "loss": 0.2169,
      "step": 1000
    },
    {
      "epoch": 0.5042436345481778,
      "grad_norm": 102.45979309082031,
      "learning_rate": 4.7719573896708694e-05,
      "loss": 0.2365,
      "step": 1010
    },
    {
      "epoch": 0.509236145781328,
      "grad_norm": 0.027035236358642578,
      "learning_rate": 4.762411565726739e-05,
      "loss": 0.0074,
      "step": 1020
    },
    {
      "epoch": 0.5142286570144783,
      "grad_norm": 0.008368775248527527,
      "learning_rate": 4.752865741782608e-05,
      "loss": 0.0815,
      "step": 1030
    },
    {
      "epoch": 0.5192211682476285,
      "grad_norm": 2.5767810344696045,
      "learning_rate": 4.7433199178384775e-05,
      "loss": 0.2047,
      "step": 1040
    },
    {
      "epoch": 0.5242136794807788,
      "grad_norm": 0.007208889350295067,
      "learning_rate": 4.733774093894347e-05,
      "loss": 0.0688,
      "step": 1050
    },
    {
      "epoch": 0.5292061907139292,
      "grad_norm": 0.0515529066324234,
      "learning_rate": 4.724228269950217e-05,
      "loss": 0.0004,
      "step": 1060
    },
    {
      "epoch": 0.5341987019470794,
      "grad_norm": 0.018211688846349716,
      "learning_rate": 4.714682446006086e-05,
      "loss": 0.0002,
      "step": 1070
    },
    {
      "epoch": 0.5391912131802297,
      "grad_norm": 0.005733289755880833,
      "learning_rate": 4.705136622061955e-05,
      "loss": 0.0003,
      "step": 1080
    },
    {
      "epoch": 0.5441837244133799,
      "grad_norm": 0.07240112870931625,
      "learning_rate": 4.695590798117825e-05,
      "loss": 0.0002,
      "step": 1090
    },
    {
      "epoch": 0.5491762356465302,
      "grad_norm": 0.002748107071965933,
      "learning_rate": 4.6860449741736943e-05,
      "loss": 0.0002,
      "step": 1100
    },
    {
      "epoch": 0.5541687468796804,
      "grad_norm": 0.0010558614740148187,
      "learning_rate": 4.676499150229564e-05,
      "loss": 0.0001,
      "step": 1110
    },
    {
      "epoch": 0.5591612581128308,
      "grad_norm": 0.0015790531178936362,
      "learning_rate": 4.6669533262854335e-05,
      "loss": 0.0001,
      "step": 1120
    },
    {
      "epoch": 0.564153769345981,
      "grad_norm": 0.0014232613611966372,
      "learning_rate": 4.6574075023413024e-05,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 0.5691462805791313,
      "grad_norm": 0.0011339712655171752,
      "learning_rate": 4.647861678397172e-05,
      "loss": 0.0001,
      "step": 1140
    },
    {
      "epoch": 0.5741387918122816,
      "grad_norm": 13.351258277893066,
      "learning_rate": 4.6383158544530416e-05,
      "loss": 0.0003,
      "step": 1150
    },
    {
      "epoch": 0.5791313030454318,
      "grad_norm": 0.0024532731622457504,
      "learning_rate": 4.6287700305089105e-05,
      "loss": 0.0001,
      "step": 1160
    },
    {
      "epoch": 0.5841238142785822,
      "grad_norm": 5.566581726074219,
      "learning_rate": 4.619224206564781e-05,
      "loss": 0.1228,
      "step": 1170
    },
    {
      "epoch": 0.5891163255117324,
      "grad_norm": 0.0012783007696270943,
      "learning_rate": 4.6096783826206497e-05,
      "loss": 0.0004,
      "step": 1180
    },
    {
      "epoch": 0.5941088367448827,
      "grad_norm": 0.00782789010554552,
      "learning_rate": 4.600132558676519e-05,
      "loss": 0.0009,
      "step": 1190
    },
    {
      "epoch": 0.5991013479780329,
      "grad_norm": 0.09816748648881912,
      "learning_rate": 4.590586734732389e-05,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 0.6040938592111832,
      "grad_norm": 0.003193835262209177,
      "learning_rate": 4.581040910788258e-05,
      "loss": 0.077,
      "step": 1210
    },
    {
      "epoch": 0.6090863704443334,
      "grad_norm": 0.012920456938445568,
      "learning_rate": 4.571495086844127e-05,
      "loss": 0.001,
      "step": 1220
    },
    {
      "epoch": 0.6140788816774838,
      "grad_norm": 0.0015935003757476807,
      "learning_rate": 4.561949262899997e-05,
      "loss": 0.0006,
      "step": 1230
    },
    {
      "epoch": 0.6190713929106341,
      "grad_norm": 0.0030881776474416256,
      "learning_rate": 4.5524034389558665e-05,
      "loss": 0.0001,
      "step": 1240
    },
    {
      "epoch": 0.6240639041437843,
      "grad_norm": 2.319129467010498,
      "learning_rate": 4.542857615011736e-05,
      "loss": 0.0004,
      "step": 1250
    },
    {
      "epoch": 0.6290564153769346,
      "grad_norm": 0.00627175671979785,
      "learning_rate": 4.533311791067605e-05,
      "loss": 0.1901,
      "step": 1260
    },
    {
      "epoch": 0.6340489266100848,
      "grad_norm": 105.19635009765625,
      "learning_rate": 4.5237659671234746e-05,
      "loss": 0.4461,
      "step": 1270
    },
    {
      "epoch": 0.6390414378432352,
      "grad_norm": 0.008650344796478748,
      "learning_rate": 4.514220143179344e-05,
      "loss": 0.1672,
      "step": 1280
    },
    {
      "epoch": 0.6440339490763854,
      "grad_norm": 0.027598921209573746,
      "learning_rate": 4.504674319235214e-05,
      "loss": 0.1653,
      "step": 1290
    },
    {
      "epoch": 0.6490264603095357,
      "grad_norm": 0.013512571342289448,
      "learning_rate": 4.495128495291083e-05,
      "loss": 0.0404,
      "step": 1300
    },
    {
      "epoch": 0.654018971542686,
      "grad_norm": 0.03109121322631836,
      "learning_rate": 4.485582671346952e-05,
      "loss": 0.0333,
      "step": 1310
    },
    {
      "epoch": 0.6590114827758362,
      "grad_norm": 0.006157951895147562,
      "learning_rate": 4.476036847402822e-05,
      "loss": 0.1089,
      "step": 1320
    },
    {
      "epoch": 0.6640039940089866,
      "grad_norm": 0.004821047652512789,
      "learning_rate": 4.466491023458691e-05,
      "loss": 0.0002,
      "step": 1330
    },
    {
      "epoch": 0.6689965052421368,
      "grad_norm": 0.003442603861913085,
      "learning_rate": 4.456945199514561e-05,
      "loss": 0.0002,
      "step": 1340
    },
    {
      "epoch": 0.6739890164752871,
      "grad_norm": 0.0028845935594290495,
      "learning_rate": 4.4473993755704305e-05,
      "loss": 0.0001,
      "step": 1350
    },
    {
      "epoch": 0.6789815277084373,
      "grad_norm": 0.0027375570498406887,
      "learning_rate": 4.4378535516262994e-05,
      "loss": 0.0551,
      "step": 1360
    },
    {
      "epoch": 0.6839740389415876,
      "grad_norm": 0.007746538612991571,
      "learning_rate": 4.428307727682169e-05,
      "loss": 0.0001,
      "step": 1370
    },
    {
      "epoch": 0.6889665501747378,
      "grad_norm": 0.001978206215426326,
      "learning_rate": 4.4187619037380386e-05,
      "loss": 0.0002,
      "step": 1380
    },
    {
      "epoch": 0.6939590614078882,
      "grad_norm": 0.0013299055863171816,
      "learning_rate": 4.4092160797939075e-05,
      "loss": 0.0001,
      "step": 1390
    },
    {
      "epoch": 0.6989515726410385,
      "grad_norm": 0.0022868220694363117,
      "learning_rate": 4.399670255849778e-05,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 0.7039440838741887,
      "grad_norm": 0.001804026192985475,
      "learning_rate": 4.390124431905647e-05,
      "loss": 0.0001,
      "step": 1410
    },
    {
      "epoch": 0.708936595107339,
      "grad_norm": 0.0013317831326276064,
      "learning_rate": 4.380578607961516e-05,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 0.7139291063404892,
      "grad_norm": 0.0012393180513754487,
      "learning_rate": 4.371032784017386e-05,
      "loss": 0.0389,
      "step": 1430
    },
    {
      "epoch": 0.7189216175736396,
      "grad_norm": 0.0036940798163414,
      "learning_rate": 4.361486960073255e-05,
      "loss": 0.0892,
      "step": 1440
    },
    {
      "epoch": 0.7239141288067898,
      "grad_norm": 0.004106780514121056,
      "learning_rate": 4.3519411361291243e-05,
      "loss": 0.0007,
      "step": 1450
    },
    {
      "epoch": 0.7289066400399401,
      "grad_norm": 0.001714808284305036,
      "learning_rate": 4.342395312184994e-05,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 0.7338991512730904,
      "grad_norm": 0.003436589613556862,
      "learning_rate": 4.3328494882408635e-05,
      "loss": 0.0001,
      "step": 1470
    },
    {
      "epoch": 0.7388916625062406,
      "grad_norm": 0.11412051320075989,
      "learning_rate": 4.323303664296733e-05,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 0.7438841737393909,
      "grad_norm": 0.0018464111490175128,
      "learning_rate": 4.313757840352602e-05,
      "loss": 0.104,
      "step": 1490
    },
    {
      "epoch": 0.7488766849725412,
      "grad_norm": 0.0015474745305255055,
      "learning_rate": 4.3042120164084716e-05,
      "loss": 0.0001,
      "step": 1500
    },
    {
      "epoch": 0.7538691962056915,
      "grad_norm": 0.001322024269029498,
      "learning_rate": 4.294666192464341e-05,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 0.7588617074388417,
      "grad_norm": 0.0043940674513578415,
      "learning_rate": 4.285120368520211e-05,
      "loss": 0.0001,
      "step": 1520
    },
    {
      "epoch": 0.763854218671992,
      "grad_norm": 0.0011268401285633445,
      "learning_rate": 4.27557454457608e-05,
      "loss": 0.0001,
      "step": 1530
    },
    {
      "epoch": 0.7688467299051422,
      "grad_norm": 0.0013362416066229343,
      "learning_rate": 4.266028720631949e-05,
      "loss": 0.1145,
      "step": 1540
    },
    {
      "epoch": 0.7738392411382926,
      "grad_norm": 0.030643709003925323,
      "learning_rate": 4.256482896687819e-05,
      "loss": 0.0998,
      "step": 1550
    },
    {
      "epoch": 0.7788317523714429,
      "grad_norm": 0.04137719050049782,
      "learning_rate": 4.246937072743688e-05,
      "loss": 0.1029,
      "step": 1560
    },
    {
      "epoch": 0.7838242636045931,
      "grad_norm": 0.029740143567323685,
      "learning_rate": 4.237391248799558e-05,
      "loss": 0.0006,
      "step": 1570
    },
    {
      "epoch": 0.7888167748377434,
      "grad_norm": 0.008345046080648899,
      "learning_rate": 4.2278454248554276e-05,
      "loss": 0.0007,
      "step": 1580
    },
    {
      "epoch": 0.7938092860708936,
      "grad_norm": 0.15665240585803986,
      "learning_rate": 4.2182996009112965e-05,
      "loss": 0.0718,
      "step": 1590
    },
    {
      "epoch": 0.7988017973040439,
      "grad_norm": 0.5231048464775085,
      "learning_rate": 4.208753776967166e-05,
      "loss": 0.001,
      "step": 1600
    },
    {
      "epoch": 0.8037943085371942,
      "grad_norm": 0.004049438983201981,
      "learning_rate": 4.199207953023035e-05,
      "loss": 0.0002,
      "step": 1610
    },
    {
      "epoch": 0.8087868197703445,
      "grad_norm": 0.0015690302243456244,
      "learning_rate": 4.1896621290789046e-05,
      "loss": 0.0002,
      "step": 1620
    },
    {
      "epoch": 0.8137793310034948,
      "grad_norm": 0.0015017414698377252,
      "learning_rate": 4.180116305134775e-05,
      "loss": 0.0506,
      "step": 1630
    },
    {
      "epoch": 0.818771842236645,
      "grad_norm": 0.0012426855973899364,
      "learning_rate": 4.170570481190644e-05,
      "loss": 0.0001,
      "step": 1640
    },
    {
      "epoch": 0.8237643534697953,
      "grad_norm": 0.0012673817109316587,
      "learning_rate": 4.161024657246513e-05,
      "loss": 0.002,
      "step": 1650
    },
    {
      "epoch": 0.8287568647029456,
      "grad_norm": 0.0014489026507362723,
      "learning_rate": 4.151478833302382e-05,
      "loss": 0.0001,
      "step": 1660
    },
    {
      "epoch": 0.8337493759360959,
      "grad_norm": 0.0009869046043604612,
      "learning_rate": 4.141933009358252e-05,
      "loss": 0.0001,
      "step": 1670
    },
    {
      "epoch": 0.8387418871692461,
      "grad_norm": 0.0020712416153401136,
      "learning_rate": 4.132387185414122e-05,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 0.8437343984023964,
      "grad_norm": 3.141587495803833,
      "learning_rate": 4.122841361469991e-05,
      "loss": 0.0012,
      "step": 1690
    },
    {
      "epoch": 0.8487269096355466,
      "grad_norm": 0.0020436719059944153,
      "learning_rate": 4.1132955375258605e-05,
      "loss": 0.0001,
      "step": 1700
    },
    {
      "epoch": 0.853719420868697,
      "grad_norm": 0.0011053128400817513,
      "learning_rate": 4.1037497135817294e-05,
      "loss": 0.0314,
      "step": 1710
    },
    {
      "epoch": 0.8587119321018473,
      "grad_norm": 0.0009366495069116354,
      "learning_rate": 4.094203889637599e-05,
      "loss": 0.0001,
      "step": 1720
    },
    {
      "epoch": 0.8637044433349975,
      "grad_norm": 0.001048416132107377,
      "learning_rate": 4.0846580656934686e-05,
      "loss": 0.094,
      "step": 1730
    },
    {
      "epoch": 0.8686969545681478,
      "grad_norm": 0.0018267633859068155,
      "learning_rate": 4.075112241749338e-05,
      "loss": 0.0001,
      "step": 1740
    },
    {
      "epoch": 0.873689465801298,
      "grad_norm": 0.0023839985951781273,
      "learning_rate": 4.065566417805208e-05,
      "loss": 0.0001,
      "step": 1750
    },
    {
      "epoch": 0.8786819770344483,
      "grad_norm": 0.004875402431935072,
      "learning_rate": 4.0560205938610774e-05,
      "loss": 0.0001,
      "step": 1760
    },
    {
      "epoch": 0.8836744882675986,
      "grad_norm": 0.0012585476506501436,
      "learning_rate": 4.046474769916946e-05,
      "loss": 0.0397,
      "step": 1770
    },
    {
      "epoch": 0.8886669995007489,
      "grad_norm": 0.0006709538283757865,
      "learning_rate": 4.036928945972816e-05,
      "loss": 0.0001,
      "step": 1780
    },
    {
      "epoch": 0.8936595107338992,
      "grad_norm": 0.0014187372289597988,
      "learning_rate": 4.0273831220286854e-05,
      "loss": 0.0001,
      "step": 1790
    },
    {
      "epoch": 0.8986520219670494,
      "grad_norm": 0.0025077806785702705,
      "learning_rate": 4.017837298084555e-05,
      "loss": 0.0001,
      "step": 1800
    },
    {
      "epoch": 0.9036445332001997,
      "grad_norm": 0.0011879070661962032,
      "learning_rate": 4.0082914741404246e-05,
      "loss": 0.0001,
      "step": 1810
    },
    {
      "epoch": 0.90863704443335,
      "grad_norm": 0.0010104182874783874,
      "learning_rate": 3.9987456501962935e-05,
      "loss": 0.0052,
      "step": 1820
    },
    {
      "epoch": 0.9136295556665003,
      "grad_norm": 0.0019988592248409986,
      "learning_rate": 3.989199826252163e-05,
      "loss": 0.0001,
      "step": 1830
    },
    {
      "epoch": 0.9186220668996505,
      "grad_norm": 0.0008753404254093766,
      "learning_rate": 3.979654002308032e-05,
      "loss": 0.0,
      "step": 1840
    },
    {
      "epoch": 0.9236145781328008,
      "grad_norm": 0.003763555083423853,
      "learning_rate": 3.970108178363902e-05,
      "loss": 0.0001,
      "step": 1850
    },
    {
      "epoch": 0.928607089365951,
      "grad_norm": 0.000991007429547608,
      "learning_rate": 3.960562354419772e-05,
      "loss": 0.1473,
      "step": 1860
    },
    {
      "epoch": 0.9335996005991013,
      "grad_norm": 0.0009478619322180748,
      "learning_rate": 3.951016530475641e-05,
      "loss": 0.0001,
      "step": 1870
    },
    {
      "epoch": 0.9385921118322517,
      "grad_norm": 0.007337411865592003,
      "learning_rate": 3.94147070653151e-05,
      "loss": 0.0001,
      "step": 1880
    },
    {
      "epoch": 0.9435846230654019,
      "grad_norm": 0.00559651805087924,
      "learning_rate": 3.931924882587379e-05,
      "loss": 0.0001,
      "step": 1890
    },
    {
      "epoch": 0.9485771342985522,
      "grad_norm": 0.0007202362176030874,
      "learning_rate": 3.922379058643249e-05,
      "loss": 0.0001,
      "step": 1900
    },
    {
      "epoch": 0.9535696455317024,
      "grad_norm": 0.0009440925205126405,
      "learning_rate": 3.912833234699119e-05,
      "loss": 0.0001,
      "step": 1910
    },
    {
      "epoch": 0.9585621567648527,
      "grad_norm": 0.0006043380126357079,
      "learning_rate": 3.903287410754988e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 0.963554667998003,
      "grad_norm": 0.001749495160765946,
      "learning_rate": 3.8937415868108576e-05,
      "loss": 0.0001,
      "step": 1930
    },
    {
      "epoch": 0.9685471792311533,
      "grad_norm": 0.0006006264011375606,
      "learning_rate": 3.8841957628667265e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 0.9735396904643036,
      "grad_norm": 0.0013682999415323138,
      "learning_rate": 3.874649938922596e-05,
      "loss": 0.0,
      "step": 1950
    },
    {
      "epoch": 0.9785322016974538,
      "grad_norm": 0.0008262417977675796,
      "learning_rate": 3.8651041149784656e-05,
      "loss": 0.0001,
      "step": 1960
    },
    {
      "epoch": 0.9835247129306041,
      "grad_norm": 0.0008710011024959385,
      "learning_rate": 3.855558291034335e-05,
      "loss": 0.0001,
      "step": 1970
    },
    {
      "epoch": 0.9885172241637543,
      "grad_norm": 0.0009476117556914687,
      "learning_rate": 3.846012467090205e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 0.9935097353969047,
      "grad_norm": 0.002019951120018959,
      "learning_rate": 3.836466643146074e-05,
      "loss": 0.0671,
      "step": 1990
    },
    {
      "epoch": 0.9985022466300549,
      "grad_norm": 0.001960469875484705,
      "learning_rate": 3.826920819201943e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.998002542218994,
      "eval_f1": 0.9980053102305637,
      "eval_loss": 0.018911486491560936,
      "eval_runtime": 38.8829,
      "eval_samples_per_second": 141.63,
      "eval_steps_per_second": 17.72,
      "step": 2003
    },
    {
      "epoch": 1.0034947578632052,
      "grad_norm": 0.001589214545674622,
      "learning_rate": 3.817374995257813e-05,
      "loss": 0.0728,
      "step": 2010
    },
    {
      "epoch": 1.0084872690963556,
      "grad_norm": 0.021693704649806023,
      "learning_rate": 3.8078291713136825e-05,
      "loss": 0.0003,
      "step": 2020
    },
    {
      "epoch": 1.0134797803295057,
      "grad_norm": 0.0025377424899488688,
      "learning_rate": 3.798283347369552e-05,
      "loss": 0.0006,
      "step": 2030
    },
    {
      "epoch": 1.018472291562656,
      "grad_norm": 0.00361918774433434,
      "learning_rate": 3.788737523425421e-05,
      "loss": 0.0002,
      "step": 2040
    },
    {
      "epoch": 1.0234648027958062,
      "grad_norm": 0.0004592329787556082,
      "learning_rate": 3.7791916994812905e-05,
      "loss": 0.0001,
      "step": 2050
    },
    {
      "epoch": 1.0284573140289566,
      "grad_norm": 0.0026801207568496466,
      "learning_rate": 3.76964587553716e-05,
      "loss": 0.0001,
      "step": 2060
    },
    {
      "epoch": 1.033449825262107,
      "grad_norm": 0.0005396011983975768,
      "learning_rate": 3.760100051593029e-05,
      "loss": 0.0001,
      "step": 2070
    },
    {
      "epoch": 1.038442336495257,
      "grad_norm": 0.002132091438397765,
      "learning_rate": 3.750554227648899e-05,
      "loss": 0.0001,
      "step": 2080
    },
    {
      "epoch": 1.0434348477284074,
      "grad_norm": 0.0006070200470276177,
      "learning_rate": 3.741008403704768e-05,
      "loss": 0.0,
      "step": 2090
    },
    {
      "epoch": 1.0484273589615576,
      "grad_norm": 0.0017986227758228779,
      "learning_rate": 3.731462579760638e-05,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 1.053419870194708,
      "grad_norm": 0.0019440014148131013,
      "learning_rate": 3.7219167558165074e-05,
      "loss": 0.0001,
      "step": 2110
    },
    {
      "epoch": 1.0584123814278583,
      "grad_norm": 0.0003454208781477064,
      "learning_rate": 3.712370931872376e-05,
      "loss": 0.0,
      "step": 2120
    },
    {
      "epoch": 1.0634048926610085,
      "grad_norm": 0.0008398258942179382,
      "learning_rate": 3.702825107928246e-05,
      "loss": 0.0,
      "step": 2130
    },
    {
      "epoch": 1.0683974038941588,
      "grad_norm": 0.0007449322147294879,
      "learning_rate": 3.693279283984116e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 1.073389915127309,
      "grad_norm": 0.0003284361446276307,
      "learning_rate": 3.683733460039985e-05,
      "loss": 0.0,
      "step": 2150
    },
    {
      "epoch": 1.0783824263604593,
      "grad_norm": 0.0009382208809256554,
      "learning_rate": 3.6741876360958546e-05,
      "loss": 0.0,
      "step": 2160
    },
    {
      "epoch": 1.0833749375936095,
      "grad_norm": 0.0008820172515697777,
      "learning_rate": 3.6646418121517235e-05,
      "loss": 0.0,
      "step": 2170
    },
    {
      "epoch": 1.0883674488267598,
      "grad_norm": 0.0005379956564866006,
      "learning_rate": 3.655095988207593e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 1.0933599600599102,
      "grad_norm": 0.0013056200696155429,
      "learning_rate": 3.645550164263463e-05,
      "loss": 0.0,
      "step": 2190
    },
    {
      "epoch": 1.0983524712930604,
      "grad_norm": 0.0009809667244553566,
      "learning_rate": 3.636004340319332e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 1.1033449825262107,
      "grad_norm": 0.0008997442200779915,
      "learning_rate": 3.626458516375202e-05,
      "loss": 0.0,
      "step": 2210
    },
    {
      "epoch": 1.1083374937593609,
      "grad_norm": 0.0005577366682700813,
      "learning_rate": 3.616912692431071e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 1.1133300049925112,
      "grad_norm": 0.0006594000151380897,
      "learning_rate": 3.60736686848694e-05,
      "loss": 0.0,
      "step": 2230
    },
    {
      "epoch": 1.1183225162256616,
      "grad_norm": 0.000725703255739063,
      "learning_rate": 3.59782104454281e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 1.1233150274588117,
      "grad_norm": 0.00037493606214411557,
      "learning_rate": 3.5882752205986795e-05,
      "loss": 0.0,
      "step": 2250
    },
    {
      "epoch": 1.128307538691962,
      "grad_norm": 0.0007157989894039929,
      "learning_rate": 3.578729396654549e-05,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 1.1333000499251122,
      "grad_norm": 0.0009760917164385319,
      "learning_rate": 3.569183572710418e-05,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 1.1382925611582626,
      "grad_norm": 0.0004132581234443933,
      "learning_rate": 3.5596377487662876e-05,
      "loss": 0.0,
      "step": 2280
    },
    {
      "epoch": 1.143285072391413,
      "grad_norm": 0.0005591081571765244,
      "learning_rate": 3.550091924822157e-05,
      "loss": 0.0,
      "step": 2290
    },
    {
      "epoch": 1.1482775836245631,
      "grad_norm": 0.00042555254185572267,
      "learning_rate": 3.540546100878026e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 1.1532700948577135,
      "grad_norm": 0.00044045201502740383,
      "learning_rate": 3.531000276933896e-05,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 1.1582626060908636,
      "grad_norm": 0.0017372852889820933,
      "learning_rate": 3.521454452989765e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 1.163255117324014,
      "grad_norm": 0.000582089473027736,
      "learning_rate": 3.511908629045635e-05,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 1.1682476285571641,
      "grad_norm": 0.0005218436708673835,
      "learning_rate": 3.5023628051015044e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 1.1732401397903145,
      "grad_norm": 0.0004126518324483186,
      "learning_rate": 3.492816981157373e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 1.1782326510234649,
      "grad_norm": 0.00037308226455934346,
      "learning_rate": 3.4832711572132436e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 1.183225162256615,
      "grad_norm": 0.0003087517980020493,
      "learning_rate": 3.4737253332691125e-05,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 1.1882176734897654,
      "grad_norm": 0.0006328963791020215,
      "learning_rate": 3.464179509324982e-05,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 1.1932101847229157,
      "grad_norm": 0.0003172205470036715,
      "learning_rate": 3.4546336853808516e-05,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 1.1982026959560659,
      "grad_norm": 0.000803993025328964,
      "learning_rate": 3.4450878614367205e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 1.2031952071892162,
      "grad_norm": 0.00038663329905830324,
      "learning_rate": 3.43554203749259e-05,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 1.2081877184223664,
      "grad_norm": 0.0002302040666108951,
      "learning_rate": 3.42599621354846e-05,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 1.2131802296555168,
      "grad_norm": 0.00037343442090786994,
      "learning_rate": 3.416450389604329e-05,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 1.218172740888667,
      "grad_norm": 0.0004537204513326287,
      "learning_rate": 3.406904565660199e-05,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 1.2231652521218173,
      "grad_norm": 0.0004450192500371486,
      "learning_rate": 3.397358741716068e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 1.2281577633549676,
      "grad_norm": 0.0003247777058277279,
      "learning_rate": 3.3878129177719374e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 1.2331502745881178,
      "grad_norm": 0.0006156996241770685,
      "learning_rate": 3.378267093827806e-05,
      "loss": 0.0,
      "step": 2470
    },
    {
      "epoch": 1.2381427858212681,
      "grad_norm": 0.0002553234517108649,
      "learning_rate": 3.3687212698836765e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 1.2431352970544183,
      "grad_norm": 0.0005020683747716248,
      "learning_rate": 3.359175445939546e-05,
      "loss": 0.0,
      "step": 2490
    },
    {
      "epoch": 1.2481278082875686,
      "grad_norm": 0.0004213400825392455,
      "learning_rate": 3.349629621995415e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 1.2531203195207188,
      "grad_norm": 0.0004534140753094107,
      "learning_rate": 3.3400837980512846e-05,
      "loss": 0.0,
      "step": 2510
    },
    {
      "epoch": 1.2581128307538691,
      "grad_norm": 0.00019716474344022572,
      "learning_rate": 3.330537974107154e-05,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 1.2631053419870195,
      "grad_norm": 0.0007670646882615983,
      "learning_rate": 3.320992150163024e-05,
      "loss": 0.0,
      "step": 2530
    },
    {
      "epoch": 1.2680978532201697,
      "grad_norm": 0.000244549592025578,
      "learning_rate": 3.3114463262188934e-05,
      "loss": 0.0,
      "step": 2540
    },
    {
      "epoch": 1.27309036445332,
      "grad_norm": 0.00023438807693310082,
      "learning_rate": 3.301900502274762e-05,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 1.2780828756864704,
      "grad_norm": 0.0003072727704420686,
      "learning_rate": 3.292354678330632e-05,
      "loss": 0.0,
      "step": 2560
    },
    {
      "epoch": 1.2830753869196205,
      "grad_norm": 0.0003019783180207014,
      "learning_rate": 3.2828088543865014e-05,
      "loss": 0.0,
      "step": 2570
    },
    {
      "epoch": 1.288067898152771,
      "grad_norm": 0.0004921117215417325,
      "learning_rate": 3.27326303044237e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 1.293060409385921,
      "grad_norm": 0.0006467135972343385,
      "learning_rate": 3.2637172064982406e-05,
      "loss": 0.0,
      "step": 2590
    },
    {
      "epoch": 1.2980529206190714,
      "grad_norm": 0.0003809767367783934,
      "learning_rate": 3.2541713825541095e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 1.3030454318522215,
      "grad_norm": 0.0013253245269879699,
      "learning_rate": 3.244625558609979e-05,
      "loss": 0.0941,
      "step": 2610
    },
    {
      "epoch": 1.308037943085372,
      "grad_norm": 0.00017752843268681318,
      "learning_rate": 3.235079734665849e-05,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 1.3130304543185223,
      "grad_norm": 0.006212135311216116,
      "learning_rate": 3.2255339107217176e-05,
      "loss": 0.0001,
      "step": 2630
    },
    {
      "epoch": 1.3180229655516724,
      "grad_norm": 0.001088864984922111,
      "learning_rate": 3.215988086777587e-05,
      "loss": 0.0001,
      "step": 2640
    },
    {
      "epoch": 1.3230154767848228,
      "grad_norm": 0.003223378211259842,
      "learning_rate": 3.206442262833457e-05,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 1.3280079880179732,
      "grad_norm": 0.0007975961780175567,
      "learning_rate": 3.196896438889326e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 1.3330004992511233,
      "grad_norm": 0.0016237114323303103,
      "learning_rate": 3.187350614945196e-05,
      "loss": 0.0,
      "step": 2670
    },
    {
      "epoch": 1.3379930104842737,
      "grad_norm": 0.00022110558347776532,
      "learning_rate": 3.177804791001065e-05,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 1.3429855217174238,
      "grad_norm": 0.0020889556035399437,
      "learning_rate": 3.1682589670569344e-05,
      "loss": 0.0,
      "step": 2690
    },
    {
      "epoch": 1.3479780329505742,
      "grad_norm": 0.0003771654737647623,
      "learning_rate": 3.158713143112804e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 1.3529705441837243,
      "grad_norm": 0.0015000305138528347,
      "learning_rate": 3.1491673191686736e-05,
      "loss": 0.0,
      "step": 2710
    },
    {
      "epoch": 1.3579630554168747,
      "grad_norm": 0.0004391488910187036,
      "learning_rate": 3.139621495224543e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 1.362955566650025,
      "grad_norm": 0.0005819897633045912,
      "learning_rate": 3.130075671280412e-05,
      "loss": 0.0,
      "step": 2730
    },
    {
      "epoch": 1.3679480778831752,
      "grad_norm": 0.0008981414721347392,
      "learning_rate": 3.1205298473362816e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 1.3729405891163255,
      "grad_norm": 0.003155941143631935,
      "learning_rate": 3.1109840233921505e-05,
      "loss": 0.0798,
      "step": 2750
    },
    {
      "epoch": 1.377933100349476,
      "grad_norm": 0.0020180554129183292,
      "learning_rate": 3.101438199448021e-05,
      "loss": 0.0003,
      "step": 2760
    },
    {
      "epoch": 1.382925611582626,
      "grad_norm": 0.0016445731744170189,
      "learning_rate": 3.0918923755038904e-05,
      "loss": 0.0001,
      "step": 2770
    },
    {
      "epoch": 1.3879181228157762,
      "grad_norm": 0.0009536047000437975,
      "learning_rate": 3.082346551559759e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 1.3929106340489266,
      "grad_norm": 0.0009615632006898522,
      "learning_rate": 3.072800727615629e-05,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 1.397903145282077,
      "grad_norm": 0.0005485292640514672,
      "learning_rate": 3.063254903671498e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 1.402895656515227,
      "grad_norm": 0.0009539310703985393,
      "learning_rate": 3.0537090797273674e-05,
      "loss": 0.0389,
      "step": 2810
    },
    {
      "epoch": 1.4078881677483774,
      "grad_norm": 0.0003346050507389009,
      "learning_rate": 3.0441632557832373e-05,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 1.4128806789815278,
      "grad_norm": 0.0006363766733556986,
      "learning_rate": 3.0346174318391065e-05,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 1.417873190214678,
      "grad_norm": 0.06278640031814575,
      "learning_rate": 3.025071607894976e-05,
      "loss": 0.2806,
      "step": 2840
    },
    {
      "epoch": 1.4228657014478283,
      "grad_norm": 0.006679096259176731,
      "learning_rate": 3.015525783950845e-05,
      "loss": 0.1179,
      "step": 2850
    },
    {
      "epoch": 1.4278582126809785,
      "grad_norm": 0.0024173681158572435,
      "learning_rate": 3.005979960006715e-05,
      "loss": 0.0001,
      "step": 2860
    },
    {
      "epoch": 1.4328507239141288,
      "grad_norm": 0.001006662962026894,
      "learning_rate": 2.9964341360625845e-05,
      "loss": 0.0001,
      "step": 2870
    },
    {
      "epoch": 1.437843235147279,
      "grad_norm": 0.0012805660953745246,
      "learning_rate": 2.9868883121184534e-05,
      "loss": 0.0001,
      "step": 2880
    },
    {
      "epoch": 1.4428357463804293,
      "grad_norm": 0.0005360650829970837,
      "learning_rate": 2.9773424881743233e-05,
      "loss": 0.0875,
      "step": 2890
    },
    {
      "epoch": 1.4478282576135797,
      "grad_norm": 0.004221260081976652,
      "learning_rate": 2.967796664230193e-05,
      "loss": 0.0003,
      "step": 2900
    },
    {
      "epoch": 1.4528207688467298,
      "grad_norm": 0.00132282474078238,
      "learning_rate": 2.958250840286062e-05,
      "loss": 0.0001,
      "step": 2910
    },
    {
      "epoch": 1.4578132800798802,
      "grad_norm": 0.001308365142904222,
      "learning_rate": 2.9487050163419318e-05,
      "loss": 0.0,
      "step": 2920
    },
    {
      "epoch": 1.4628057913130306,
      "grad_norm": 0.0005335345049388707,
      "learning_rate": 2.9391591923978007e-05,
      "loss": 0.0091,
      "step": 2930
    },
    {
      "epoch": 1.4677983025461807,
      "grad_norm": 0.00046456270501948893,
      "learning_rate": 2.9296133684536702e-05,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 1.472790813779331,
      "grad_norm": 0.002150643151253462,
      "learning_rate": 2.9200675445095402e-05,
      "loss": 0.0197,
      "step": 2950
    },
    {
      "epoch": 1.4777833250124812,
      "grad_norm": 0.0014398571802303195,
      "learning_rate": 2.910521720565409e-05,
      "loss": 0.0001,
      "step": 2960
    },
    {
      "epoch": 1.4827758362456316,
      "grad_norm": 0.0006371423951350152,
      "learning_rate": 2.9009758966212787e-05,
      "loss": 0.1015,
      "step": 2970
    },
    {
      "epoch": 1.4877683474787817,
      "grad_norm": 0.0007472119177691638,
      "learning_rate": 2.891430072677148e-05,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 1.492760858711932,
      "grad_norm": 0.0023673749528825283,
      "learning_rate": 2.8818842487330175e-05,
      "loss": 0.0001,
      "step": 2990
    },
    {
      "epoch": 1.4977533699450825,
      "grad_norm": 0.0011106490856036544,
      "learning_rate": 2.872338424788887e-05,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 1.5027458811782326,
      "grad_norm": 0.0013035561423748732,
      "learning_rate": 2.8627926008447563e-05,
      "loss": 0.0884,
      "step": 3010
    },
    {
      "epoch": 1.507738392411383,
      "grad_norm": 0.002851048018783331,
      "learning_rate": 2.853246776900626e-05,
      "loss": 0.0001,
      "step": 3020
    },
    {
      "epoch": 1.5127309036445333,
      "grad_norm": 0.09033336490392685,
      "learning_rate": 2.8437009529564955e-05,
      "loss": 0.0003,
      "step": 3030
    },
    {
      "epoch": 1.5177234148776835,
      "grad_norm": 0.00464892853051424,
      "learning_rate": 2.8341551290123647e-05,
      "loss": 0.0001,
      "step": 3040
    },
    {
      "epoch": 1.5227159261108336,
      "grad_norm": 0.0022821426391601562,
      "learning_rate": 2.824609305068234e-05,
      "loss": 0.0758,
      "step": 3050
    },
    {
      "epoch": 1.527708437343984,
      "grad_norm": 0.0007497681071981788,
      "learning_rate": 2.8150634811241036e-05,
      "loss": 0.0001,
      "step": 3060
    },
    {
      "epoch": 1.5327009485771343,
      "grad_norm": 0.0030900388956069946,
      "learning_rate": 2.805517657179973e-05,
      "loss": 0.0001,
      "step": 3070
    },
    {
      "epoch": 1.5376934598102845,
      "grad_norm": 0.0008607271010987461,
      "learning_rate": 2.7959718332358424e-05,
      "loss": 0.0001,
      "step": 3080
    },
    {
      "epoch": 1.5426859710434349,
      "grad_norm": 0.0008349770214408636,
      "learning_rate": 2.786426009291712e-05,
      "loss": 0.0,
      "step": 3090
    },
    {
      "epoch": 1.5476784822765852,
      "grad_norm": 0.0006185344536788762,
      "learning_rate": 2.7768801853475812e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 1.5526709935097354,
      "grad_norm": 0.0007305452600121498,
      "learning_rate": 2.7673343614034505e-05,
      "loss": 0.0,
      "step": 3110
    },
    {
      "epoch": 1.5576635047428855,
      "grad_norm": 0.0005265554063953459,
      "learning_rate": 2.7577885374593204e-05,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 1.562656015976036,
      "grad_norm": 0.0008637614664621651,
      "learning_rate": 2.7482427135151896e-05,
      "loss": 0.0,
      "step": 3130
    },
    {
      "epoch": 1.5676485272091862,
      "grad_norm": 0.000545445189345628,
      "learning_rate": 2.738696889571059e-05,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 1.5726410384423364,
      "grad_norm": 0.0012065029004588723,
      "learning_rate": 2.7291510656269285e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 1.5776335496754867,
      "grad_norm": 0.0003596295427996665,
      "learning_rate": 2.719605241682798e-05,
      "loss": 0.1032,
      "step": 3160
    },
    {
      "epoch": 1.5826260609086371,
      "grad_norm": 0.005469547584652901,
      "learning_rate": 2.7100594177386676e-05,
      "loss": 0.0001,
      "step": 3170
    },
    {
      "epoch": 1.5876185721417873,
      "grad_norm": 0.0026375192683190107,
      "learning_rate": 2.700513593794537e-05,
      "loss": 0.0005,
      "step": 3180
    },
    {
      "epoch": 1.5926110833749376,
      "grad_norm": 0.0008058810490183532,
      "learning_rate": 2.690967769850406e-05,
      "loss": 0.0001,
      "step": 3190
    },
    {
      "epoch": 1.597603594608088,
      "grad_norm": 0.026375746354460716,
      "learning_rate": 2.6814219459062757e-05,
      "loss": 0.0001,
      "step": 3200
    },
    {
      "epoch": 1.6025961058412381,
      "grad_norm": 0.000574341625906527,
      "learning_rate": 2.6718761219621453e-05,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 1.6075886170743883,
      "grad_norm": 0.0005278342869132757,
      "learning_rate": 2.6623302980180145e-05,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 1.6125811283075389,
      "grad_norm": 0.000483000825624913,
      "learning_rate": 2.652784474073884e-05,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 1.617573639540689,
      "grad_norm": 0.00127159315161407,
      "learning_rate": 2.6432386501297533e-05,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 1.6225661507738391,
      "grad_norm": 0.0015500948065891862,
      "learning_rate": 2.6336928261856226e-05,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 1.6275586620069895,
      "grad_norm": 0.000490575737785548,
      "learning_rate": 2.6241470022414925e-05,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 1.6325511732401399,
      "grad_norm": 0.01047488022595644,
      "learning_rate": 2.6146011782973618e-05,
      "loss": 0.1164,
      "step": 3270
    },
    {
      "epoch": 1.63754368447329,
      "grad_norm": 0.008039530366659164,
      "learning_rate": 2.605055354353231e-05,
      "loss": 0.034,
      "step": 3280
    },
    {
      "epoch": 1.6425361957064404,
      "grad_norm": 0.002920705359429121,
      "learning_rate": 2.5955095304091006e-05,
      "loss": 0.0002,
      "step": 3290
    },
    {
      "epoch": 1.6475287069395907,
      "grad_norm": 0.00100624468177557,
      "learning_rate": 2.58596370646497e-05,
      "loss": 0.0001,
      "step": 3300
    },
    {
      "epoch": 1.652521218172741,
      "grad_norm": 0.0007537126075476408,
      "learning_rate": 2.5764178825208394e-05,
      "loss": 0.0067,
      "step": 3310
    },
    {
      "epoch": 1.657513729405891,
      "grad_norm": 0.000570157018955797,
      "learning_rate": 2.566872058576709e-05,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 1.6625062406390414,
      "grad_norm": 0.0006636499310843647,
      "learning_rate": 2.5573262346325782e-05,
      "loss": 0.0,
      "step": 3330
    },
    {
      "epoch": 1.6674987518721918,
      "grad_norm": 0.0005637675640173256,
      "learning_rate": 2.5477804106884478e-05,
      "loss": 0.0818,
      "step": 3340
    },
    {
      "epoch": 1.672491263105342,
      "grad_norm": 0.0005598980933427811,
      "learning_rate": 2.5382345867443174e-05,
      "loss": 0.0922,
      "step": 3350
    },
    {
      "epoch": 1.6774837743384923,
      "grad_norm": 0.0011089296313002706,
      "learning_rate": 2.5286887628001867e-05,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 1.6824762855716426,
      "grad_norm": 0.001198116922751069,
      "learning_rate": 2.5191429388560562e-05,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 1.6874687968047928,
      "grad_norm": 0.0016899975016713142,
      "learning_rate": 2.5095971149119255e-05,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 1.692461308037943,
      "grad_norm": 0.0009331614710390568,
      "learning_rate": 2.5000512909677947e-05,
      "loss": 0.0,
      "step": 3390
    },
    {
      "epoch": 1.6974538192710935,
      "grad_norm": 0.0008078539394773543,
      "learning_rate": 2.4905054670236646e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 1.7024463305042437,
      "grad_norm": 0.0008968893089331686,
      "learning_rate": 2.480959643079534e-05,
      "loss": 0.0278,
      "step": 3410
    },
    {
      "epoch": 1.7074388417373938,
      "grad_norm": 0.000697533949278295,
      "learning_rate": 2.471413819135403e-05,
      "loss": 0.0001,
      "step": 3420
    },
    {
      "epoch": 1.7124313529705442,
      "grad_norm": 0.0005428377771750093,
      "learning_rate": 2.4618679951912727e-05,
      "loss": 0.0001,
      "step": 3430
    },
    {
      "epoch": 1.7174238642036945,
      "grad_norm": 0.0017576079117134213,
      "learning_rate": 2.452322171247142e-05,
      "loss": 0.0001,
      "step": 3440
    },
    {
      "epoch": 1.7224163754368447,
      "grad_norm": 0.0019632987678050995,
      "learning_rate": 2.4427763473030116e-05,
      "loss": 0.0097,
      "step": 3450
    },
    {
      "epoch": 1.727408886669995,
      "grad_norm": 0.0014049226883798838,
      "learning_rate": 2.433230523358881e-05,
      "loss": 0.0001,
      "step": 3460
    },
    {
      "epoch": 1.7324013979031454,
      "grad_norm": 0.0023024803958833218,
      "learning_rate": 2.4236846994147504e-05,
      "loss": 0.0001,
      "step": 3470
    },
    {
      "epoch": 1.7373939091362955,
      "grad_norm": 0.0008971652714535594,
      "learning_rate": 2.4141388754706196e-05,
      "loss": 0.0001,
      "step": 3480
    },
    {
      "epoch": 1.7423864203694457,
      "grad_norm": 0.0006750529282726347,
      "learning_rate": 2.4045930515264892e-05,
      "loss": 0.0,
      "step": 3490
    },
    {
      "epoch": 1.747378931602596,
      "grad_norm": 0.0005625173216685653,
      "learning_rate": 2.3950472275823588e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 1.7523714428357464,
      "grad_norm": 0.0009622787474654615,
      "learning_rate": 2.385501403638228e-05,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 1.7573639540688966,
      "grad_norm": 0.0007160023669712245,
      "learning_rate": 2.3759555796940976e-05,
      "loss": 0.0,
      "step": 3520
    },
    {
      "epoch": 1.762356465302047,
      "grad_norm": 0.0008490859181620181,
      "learning_rate": 2.366409755749967e-05,
      "loss": 0.0,
      "step": 3530
    },
    {
      "epoch": 1.7673489765351973,
      "grad_norm": 0.000715659698471427,
      "learning_rate": 2.3568639318058368e-05,
      "loss": 0.0,
      "step": 3540
    },
    {
      "epoch": 1.7723414877683474,
      "grad_norm": 0.0008534127846360207,
      "learning_rate": 2.347318107861706e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 1.7773339990014978,
      "grad_norm": 0.0005991093348711729,
      "learning_rate": 2.3377722839175753e-05,
      "loss": 0.0,
      "step": 3560
    },
    {
      "epoch": 1.7823265102346482,
      "grad_norm": 0.0006439742282964289,
      "learning_rate": 2.328226459973445e-05,
      "loss": 0.0,
      "step": 3570
    },
    {
      "epoch": 1.7873190214677983,
      "grad_norm": 0.00037922110641375184,
      "learning_rate": 2.318680636029314e-05,
      "loss": 0.0,
      "step": 3580
    },
    {
      "epoch": 1.7923115327009485,
      "grad_norm": 0.0004143767000641674,
      "learning_rate": 2.3091348120851837e-05,
      "loss": 0.0,
      "step": 3590
    },
    {
      "epoch": 1.7973040439340988,
      "grad_norm": 0.0006929004448466003,
      "learning_rate": 2.2995889881410533e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 1.8022965551672492,
      "grad_norm": 0.000387213978683576,
      "learning_rate": 2.2900431641969225e-05,
      "loss": 0.0,
      "step": 3610
    },
    {
      "epoch": 1.8072890664003993,
      "grad_norm": 0.0005729069234803319,
      "learning_rate": 2.2804973402527918e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 1.8122815776335497,
      "grad_norm": 0.000311233481625095,
      "learning_rate": 2.2709515163086613e-05,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 1.8172740888667,
      "grad_norm": 0.00041893235174939036,
      "learning_rate": 2.261405692364531e-05,
      "loss": 0.0,
      "step": 3640
    },
    {
      "epoch": 1.8222666000998502,
      "grad_norm": 0.0006855251267552376,
      "learning_rate": 2.2518598684204e-05,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 1.8272591113330003,
      "grad_norm": 0.0005845575942657888,
      "learning_rate": 2.2423140444762698e-05,
      "loss": 0.0,
      "step": 3660
    },
    {
      "epoch": 1.832251622566151,
      "grad_norm": 0.0006211617146618664,
      "learning_rate": 2.232768220532139e-05,
      "loss": 0.0,
      "step": 3670
    },
    {
      "epoch": 1.837244133799301,
      "grad_norm": 0.00032555608777329326,
      "learning_rate": 2.2232223965880082e-05,
      "loss": 0.0,
      "step": 3680
    },
    {
      "epoch": 1.8422366450324512,
      "grad_norm": 0.00041625823359936476,
      "learning_rate": 2.213676572643878e-05,
      "loss": 0.0,
      "step": 3690
    },
    {
      "epoch": 1.8472291562656016,
      "grad_norm": 0.0003756778023671359,
      "learning_rate": 2.2041307486997474e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 1.852221667498752,
      "grad_norm": 0.0005108646000735462,
      "learning_rate": 2.194584924755617e-05,
      "loss": 0.0,
      "step": 3710
    },
    {
      "epoch": 1.857214178731902,
      "grad_norm": 0.0005483799031935632,
      "learning_rate": 2.1850391008114862e-05,
      "loss": 0.0,
      "step": 3720
    },
    {
      "epoch": 1.8622066899650525,
      "grad_norm": 0.00040483451448380947,
      "learning_rate": 2.1754932768673558e-05,
      "loss": 0.0,
      "step": 3730
    },
    {
      "epoch": 1.8671992011982028,
      "grad_norm": 0.00035621048300527036,
      "learning_rate": 2.1659474529232254e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 1.872191712431353,
      "grad_norm": 0.00025740661658346653,
      "learning_rate": 2.1564016289790946e-05,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 1.877184223664503,
      "grad_norm": 0.000695627648383379,
      "learning_rate": 2.146855805034964e-05,
      "loss": 0.1206,
      "step": 3760
    },
    {
      "epoch": 1.8821767348976535,
      "grad_norm": 0.0008693341515026987,
      "learning_rate": 2.1373099810908335e-05,
      "loss": 0.0001,
      "step": 3770
    },
    {
      "epoch": 1.8871692461308038,
      "grad_norm": 0.0009675762848928571,
      "learning_rate": 2.127764157146703e-05,
      "loss": 0.0986,
      "step": 3780
    },
    {
      "epoch": 1.892161757363954,
      "grad_norm": 0.0013494972372427583,
      "learning_rate": 2.1182183332025723e-05,
      "loss": 0.0001,
      "step": 3790
    },
    {
      "epoch": 1.8971542685971043,
      "grad_norm": 0.0018268181011080742,
      "learning_rate": 2.108672509258442e-05,
      "loss": 0.0866,
      "step": 3800
    },
    {
      "epoch": 1.9021467798302547,
      "grad_norm": 0.0030601583421230316,
      "learning_rate": 2.099126685314311e-05,
      "loss": 0.0001,
      "step": 3810
    },
    {
      "epoch": 1.9071392910634049,
      "grad_norm": 0.0015023141168057919,
      "learning_rate": 2.0895808613701804e-05,
      "loss": 0.0,
      "step": 3820
    },
    {
      "epoch": 1.9121318022965552,
      "grad_norm": 0.0005108428886160254,
      "learning_rate": 2.0800350374260503e-05,
      "loss": 0.0,
      "step": 3830
    },
    {
      "epoch": 1.9171243135297056,
      "grad_norm": 0.0006117122829891741,
      "learning_rate": 2.0704892134819195e-05,
      "loss": 0.0,
      "step": 3840
    },
    {
      "epoch": 1.9221168247628557,
      "grad_norm": 0.00046666248817928135,
      "learning_rate": 2.0609433895377888e-05,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 1.9271093359960059,
      "grad_norm": 0.0003761467814911157,
      "learning_rate": 2.0513975655936584e-05,
      "loss": 0.0,
      "step": 3860
    },
    {
      "epoch": 1.9321018472291562,
      "grad_norm": 0.0006231545121408999,
      "learning_rate": 2.0418517416495276e-05,
      "loss": 0.0,
      "step": 3870
    },
    {
      "epoch": 1.9370943584623066,
      "grad_norm": 0.0006296713836491108,
      "learning_rate": 2.0323059177053972e-05,
      "loss": 0.0,
      "step": 3880
    },
    {
      "epoch": 1.9420868696954567,
      "grad_norm": 0.0009961583418771625,
      "learning_rate": 2.0227600937612668e-05,
      "loss": 0.1259,
      "step": 3890
    },
    {
      "epoch": 1.947079380928607,
      "grad_norm": 0.0011182503076270223,
      "learning_rate": 2.013214269817136e-05,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 1.9520718921617575,
      "grad_norm": 0.01141839288175106,
      "learning_rate": 2.0036684458730056e-05,
      "loss": 0.0001,
      "step": 3910
    },
    {
      "epoch": 1.9570644033949076,
      "grad_norm": 0.0037837796844542027,
      "learning_rate": 1.9941226219288752e-05,
      "loss": 0.0001,
      "step": 3920
    },
    {
      "epoch": 1.9620569146280578,
      "grad_norm": 0.0008455688366666436,
      "learning_rate": 1.9845767979847444e-05,
      "loss": 0.0897,
      "step": 3930
    },
    {
      "epoch": 1.9670494258612083,
      "grad_norm": 0.001068992423824966,
      "learning_rate": 1.975030974040614e-05,
      "loss": 0.0001,
      "step": 3940
    },
    {
      "epoch": 1.9720419370943585,
      "grad_norm": 0.0010457060998305678,
      "learning_rate": 1.9654851500964833e-05,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 1.9770344483275086,
      "grad_norm": 0.0006709059816785157,
      "learning_rate": 1.9559393261523525e-05,
      "loss": 0.0,
      "step": 3960
    },
    {
      "epoch": 1.982026959560659,
      "grad_norm": 0.0008344240486621857,
      "learning_rate": 1.9463935022082224e-05,
      "loss": 0.0,
      "step": 3970
    },
    {
      "epoch": 1.9870194707938094,
      "grad_norm": 0.003009696723893285,
      "learning_rate": 1.9368476782640917e-05,
      "loss": 0.0,
      "step": 3980
    },
    {
      "epoch": 1.9920119820269595,
      "grad_norm": 0.0009335539652965963,
      "learning_rate": 1.927301854319961e-05,
      "loss": 0.0,
      "step": 3990
    },
    {
      "epoch": 1.9970044932601099,
      "grad_norm": 0.0014194250106811523,
      "learning_rate": 1.9177560303758305e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9990920646449972,
      "eval_f1": 0.9990962292706679,
      "eval_loss": 0.007847392000257969,
      "eval_runtime": 38.8418,
      "eval_samples_per_second": 141.78,
      "eval_steps_per_second": 17.739,
      "step": 4006
    }
  ],
  "logging_steps": 10,
  "max_steps": 6009,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1561938452647200.0,
  "train_batch_size": 11,
  "trial_name": null,
  "trial_params": null
}
