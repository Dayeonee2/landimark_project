{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>category02</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>너무 목이 마른데요, 혹시 정수기 같은 건 없나요?</td>\n",
       "      <td>정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.</td>\n",
       "      <td>29.대기실 및 진료실 위치 안내</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>교정기가 떨어진 것 같아서 붙이러 왔어요.</td>\n",
       "      <td>접수 먼저 부탁드립니다. 카운터에서 성함을 입력해 주시길 바랍니다.</td>\n",
       "      <td>27.진료 접수 안내</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>앞으로 얼마나 나아지는지 보고 아프면 오라고 하네요. 제가 다음에 예약하고 와도 되죠?</td>\n",
       "      <td>예약하실 때 지난 번 진료 기록이 있다고 말씀해 주시길 부탁 드립니다. 감사합니다.</td>\n",
       "      <td>33.다음 진료실 예약</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이것도 수납용 키오스크인가요? 대기 줄이 너무 길어서요.</td>\n",
       "      <td>이곳에서도 수납 진행 가능합니다. 홈버튼을 누른 후 수납 버튼을 누르십시오.</td>\n",
       "      <td>31.수납 방법 안내</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>주사실 안에 가서 있으라는데 주사실이 어딘데요?</td>\n",
       "      <td>침을 맞는 곳이라 이름이 주사실입니다. 3층으로 올라가시면 됩니다.</td>\n",
       "      <td>29.대기실 및 진료실 위치 안내</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  \\\n",
       "0                      너무 목이 마른데요, 혹시 정수기 같은 건 없나요?   \n",
       "1                           교정기가 떨어진 것 같아서 붙이러 왔어요.   \n",
       "2  앞으로 얼마나 나아지는지 보고 아프면 오라고 하네요. 제가 다음에 예약하고 와도 되죠?   \n",
       "3                   이것도 수납용 키오스크인가요? 대기 줄이 너무 길어서요.   \n",
       "4                        주사실 안에 가서 있으라는데 주사실이 어딘데요?   \n",
       "\n",
       "                                           answer          category02  label  \n",
       "0                   정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.  29.대기실 및 진료실 위치 안내      0  \n",
       "1           접수 먼저 부탁드립니다. 카운터에서 성함을 입력해 주시길 바랍니다.         27.진료 접수 안내      1  \n",
       "2  예약하실 때 지난 번 진료 기록이 있다고 말씀해 주시길 부탁 드립니다. 감사합니다.        33.다음 진료실 예약      2  \n",
       "3      이곳에서도 수납 진행 가능합니다. 홈버튼을 누른 후 수납 버튼을 누르십시오.         31.수납 방법 안내      3  \n",
       "4           침을 맞는 곳이라 이름이 주사실입니다. 3층으로 올라가시면 됩니다.  29.대기실 및 진료실 위치 안내      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('file/health_result_label2.csv')\n",
    "\n",
    "# 질문 리스트\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# fine-tuning된 모델과 토크나이저 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_model_previous\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model_previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsek\\AppData\\Local\\Temp\\ipykernel_8504\\2153087946.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  question_embeddings = torch.load('embeddings/previous_question_embeddings.pth')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# numpy의 _reconstruct 함수를 허용 목록에 추가\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])\n",
    "\n",
    "# 신뢰할 수 있는 데이터 파일을 로드\n",
    "question_embeddings = torch.load('embeddings/previous_question_embeddings.pth')\n",
    "\n",
    "# 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "def get_embedding(input_question, tokenizer, model):\n",
    "    # 입력 문장을 토크나이즈\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # hidden states를 포함하도록 설정\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # 마지막 hidden state에서 [CLS] 토큰의 임베딩을 가져옴\n",
    "        cls_embedding = outputs.hidden_states[-1][:, 0, :]  # [CLS] 토큰의 임베딩\n",
    "        \n",
    "    return cls_embedding.squeeze().numpy()  # numpy 배열로 반환\n",
    "\n",
    "\n",
    "\n",
    "# 코사인 유사도를 계산하여 가장 유사한 답변을 찾는 함수\n",
    "def find_most_similar_answer_cosine(input_question, question_embeddings, answers, tokenizer, model):\n",
    "    # 입력 질문 임베딩 생성\n",
    "    input_embedding = get_embedding(input_question, tokenizer, model)\n",
    "\n",
    "    max_similarity = -1\n",
    "    best_answer = None\n",
    "    \n",
    "    # 각 질문 임베딩과 유사도 비교\n",
    "    for i, question_embedding in enumerate(question_embeddings):\n",
    "        # question_embedding을 텐서로 변환하고 차원 맞추기\n",
    "        question_embedding_tensor = torch.tensor(question_embedding).unsqueeze(0)  # (1, 768)\n",
    "        \n",
    "        # input_embedding도 텐서로 변환하고 차원 맞추기\n",
    "        input_embedding_tensor = torch.tensor(input_embedding).unsqueeze(0)  # (1, 768)\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        similarity = F.cosine_similarity(input_embedding_tensor, question_embedding_tensor).item()\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = answers[i]\n",
    "\n",
    "    return best_answer, max_similarity  # 유사도 반환 추가\n",
    "\n",
    "# 챗봇 응답 함수\n",
    "def chatbot_response(input_question, tokenizer, model, question_embeddings, answers):\n",
    "    # 1차 필터링: 분류 모델로 레이블 예측\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 2차 필터링: 같은 카테고리 내에서 코사인 유사도 계산\n",
    "    # 같은 레이블의 질문들과 임베딩 필터링\n",
    "    filtered_df = df[df['label'] == predicted_label]\n",
    "    filtered_indices = filtered_df.index.tolist()\n",
    "\n",
    "    # 필터링된 질문에 해당하는 미리 계산된 임베딩과 답변 가져오기\n",
    "    filtered_question_embeddings = [question_embeddings[i] for i in filtered_indices]\n",
    "    filtered_answers = [answers[i] for i in filtered_indices]\n",
    "\n",
    "    # 코사인 유사도를 통해 가장 유사한 답변 찾기\n",
    "    best_answer, cosine_similarity = find_most_similar_answer_cosine(input_question, filtered_question_embeddings, filtered_answers, tokenizer, model)\n",
    "    \n",
    "    return best_answer, cosine_similarity, predicted_label  # 세 가지 값 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 2\n",
      "최고 유사도 답변: 죄송하지만 접수 마감시간인 6시 30분까지는 방문해 주셔야 합니다.\n",
      "코사인 유사도: 1.000000238418579\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"예약은 이미 전화로 끝냈습니다. 안 도와줘도 괜찮아요.\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 0\n",
      "최고 유사도 답변: 정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.\n",
      "코사인 유사도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"너무 목이 마른데요, 혹시 정수기 같은 건 없나요?\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsek\\AppData\\Local\\Temp\\ipykernel_8504\\3539852570.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  question_embeddings = torch.load('embeddings/previous_question_embeddings.pth')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# 데이터프레임 로드\n",
    "df = pd.read_csv('file/health_result_label2.csv')\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "# 신뢰할 수 있는 데이터 파일을 로드\n",
    "question_embeddings = torch.load('embeddings/previous_question_embeddings.pth')\n",
    "model.eval()\n",
    "\n",
    "def get_embedding(input_question, tokenizer, model):\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        cls_embedding = outputs.hidden_states[-1][:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "def find_most_similar_answer_cosine(input_question, question_embeddings, answers, tokenizer, model):\n",
    "    input_embedding = get_embedding(input_question, tokenizer, model)\n",
    "    max_similarity = -1\n",
    "    best_answer = None\n",
    "    \n",
    "    for i, question_embedding in enumerate(question_embeddings):\n",
    "        question_embedding_tensor = torch.tensor(question_embedding).unsqueeze(0)\n",
    "        input_embedding_tensor = torch.tensor(input_embedding).unsqueeze(0)\n",
    "        similarity = F.cosine_similarity(input_embedding_tensor, question_embedding_tensor).item()\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = answers[i]\n",
    "\n",
    "    return best_answer, max_similarity\n",
    "\n",
    "def chatbot_response(input_question, tokenizer, model, question_embeddings, answers):\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    filtered_df = df[df['label'] == predicted_label]\n",
    "\n",
    "    filtered_indices = filtered_df.index.tolist()\n",
    "    filtered_question_embeddings = [question_embeddings[i] for i in filtered_indices]\n",
    "    filtered_answers = [answers[i] for i in filtered_indices]\n",
    "\n",
    "    best_answer, cosine_similarity = find_most_similar_answer_cosine(input_question, filtered_question_embeddings, filtered_answers, tokenizer, model)\n",
    "    \n",
    "    return best_answer, cosine_similarity, predicted_label\n",
    "\n",
    "# 엑셀 파일에서 질문 데이터 읽어오기\n",
    "df_test = pd.read_excel('file/test_question.xlsx')\n",
    "test_questions = df_test.groupby('label')['question'].apply(list).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>best_answer</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>화상연고도 처방이 되나요?</td>\n",
       "      <td>0</td>\n",
       "      <td>우측 복도 끝에 위치해 있습니다. 심리평가실까지 안내해 드리겠습니다.</td>\n",
       "      <td>0.99935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘 두시 삼십분에 예약했어요. 언제 들어가나요?</td>\n",
       "      <td>1</td>\n",
       "      <td>긴급상황이라면 응급실로 이동하셔서 진료 보실 수 있습니다. 응급실 건물로 가주시면 ...</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>예약한 시간보다 조금 늦었어요. 다시 접수해야 하나요?</td>\n",
       "      <td>1</td>\n",
       "      <td>반갑습니다. 1층 통합 창구에서 번호표를 뽑고 기다려 주시면 안내 도와드리겠습니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>피가 계속 나는데, 저 죽는 걸까요?</td>\n",
       "      <td>1</td>\n",
       "      <td>1층 창구에서 진료 접수를 할 수 있습니다. 저를 따라오시면 안내해 드리겠습니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>접수 재등록해도 되나요?</td>\n",
       "      <td>1</td>\n",
       "      <td>현재 고객님 앞의 대기자가 0명이기 때문에 즉시 진료 보실 수 있습니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>오래된 상처 흉터도 없어질까요?</td>\n",
       "      <td>5</td>\n",
       "      <td>정밀 검사 후에 감마 상태를 보고 결정될 것 같습니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여기 한의원도 같이 하나요? 침을 맡고 싶어요.</td>\n",
       "      <td>1</td>\n",
       "      <td>맞습니다. 증상 상담 시 자세한 증상을 알려주시길 부탁드립니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>목 디스크 때문에 잠을 잘 수 없어요. 어떤 치료를 받을 수 있나요?</td>\n",
       "      <td>5</td>\n",
       "      <td>상담 접수를 진행하였습니다. 접수 완료 문자를 등록된 번호로 전송합니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>탈모 초기 인 것 같아요. 머리카락이 자꾸 빠지는데, 이것도 진료를 볼 수 있나요?</td>\n",
       "      <td>5</td>\n",
       "      <td>의사선생님이 오시면 환자분의 증상에 대한 자세한 상담을 받으실 수 있습니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>저는 아니고, 제 아이가 열이 자꾸 오르다 말다 해요. 소아과도 진료 하나요?</td>\n",
       "      <td>5</td>\n",
       "      <td>상담 접수를 진행하였습니다. 접수 완료 문자를 등록된 번호로 전송합니다.</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  predicted_label  \\\n",
       "0                                  화상연고도 처방이 되나요?                0   \n",
       "1                     오늘 두시 삼십분에 예약했어요. 언제 들어가나요?                1   \n",
       "2                  예약한 시간보다 조금 늦었어요. 다시 접수해야 하나요?                1   \n",
       "3                            피가 계속 나는데, 저 죽는 걸까요?                1   \n",
       "4                                   접수 재등록해도 되나요?                1   \n",
       "5                               오래된 상처 흉터도 없어질까요?                5   \n",
       "6                      여기 한의원도 같이 하나요? 침을 맡고 싶어요.                1   \n",
       "7          목 디스크 때문에 잠을 잘 수 없어요. 어떤 치료를 받을 수 있나요?                5   \n",
       "8  탈모 초기 인 것 같아요. 머리카락이 자꾸 빠지는데, 이것도 진료를 볼 수 있나요?                5   \n",
       "9     저는 아니고, 제 아이가 열이 자꾸 오르다 말다 해요. 소아과도 진료 하나요?                5   \n",
       "\n",
       "                                         best_answer  cosine_similarity  \n",
       "0             우측 복도 끝에 위치해 있습니다. 심리평가실까지 안내해 드리겠습니다.            0.99935  \n",
       "1  긴급상황이라면 응급실로 이동하셔서 진료 보실 수 있습니다. 응급실 건물로 가주시면 ...            1.00000  \n",
       "2     반갑습니다. 1층 통합 창구에서 번호표를 뽑고 기다려 주시면 안내 도와드리겠습니다.            1.00000  \n",
       "3      1층 창구에서 진료 접수를 할 수 있습니다. 저를 따라오시면 안내해 드리겠습니다.            1.00000  \n",
       "4           현재 고객님 앞의 대기자가 0명이기 때문에 즉시 진료 보실 수 있습니다.            1.00000  \n",
       "5                     정밀 검사 후에 감마 상태를 보고 결정될 것 같습니다.            1.00000  \n",
       "6                맞습니다. 증상 상담 시 자세한 증상을 알려주시길 부탁드립니다.            1.00000  \n",
       "7           상담 접수를 진행하였습니다. 접수 완료 문자를 등록된 번호로 전송합니다.            1.00000  \n",
       "8         의사선생님이 오시면 환자분의 증상에 대한 자세한 상담을 받으실 수 있습니다.            1.00000  \n",
       "9           상담 접수를 진행하였습니다. 접수 완료 문자를 등록된 번호로 전송합니다.            1.00000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 질문을 리스트로 변환하여 input_questions에 저장\n",
    "input_questions = []\n",
    "for questions in test_questions.values():\n",
    "    input_questions.extend(questions)  # 각 레이블에 해당하는 질문을 추가\n",
    "\n",
    "input_questions\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# 각 질문에 대해 챗봇 응답 호출\n",
    "for input_question in input_questions:\n",
    "    best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "    \n",
    "    # 결과를 리스트에 추가\n",
    "    results.append({\n",
    "        \"question\": input_question,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"best_answer\": best_answer,\n",
    "        \"cosine_similarity\": cosine_similarity\n",
    "    })\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과 출력\n",
    "results_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 CSV 파일로 저장\n",
    "results_df.to_csv('result csv/chatbot_responses_bayesian_previous.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('result csv/chatbot_responses_bayesian_previous.csv')\n",
    "result[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
