{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>category02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>너무 목이 마른데요, 혹시 정수기 같은 건 없나요?</td>\n",
       "      <td>정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.</td>\n",
       "      <td>29.대기실 및 진료실 위치 안내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>교정기가 떨어진 것 같아서 붙이러 왔어요.</td>\n",
       "      <td>접수 먼저 부탁드립니다. 카운터에서 성함을 입력해 주시길 바랍니다.</td>\n",
       "      <td>27.진료 접수 안내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>앞으로 얼마나 나아지는지 보고 아프면 오라고 하네요. 제가 다음에 예약하고 와도 되죠?</td>\n",
       "      <td>예약하실 때 지난 번 진료 기록이 있다고 말씀해 주시길 부탁 드립니다. 감사합니다.</td>\n",
       "      <td>33.다음 진료실 예약</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이것도 수납용 키오스크인가요? 대기 줄이 너무 길어서요.</td>\n",
       "      <td>이곳에서도 수납 진행 가능합니다. 홈버튼을 누른 후 수납 버튼을 누르십시오.</td>\n",
       "      <td>31.수납 방법 안내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>주사실 안에 가서 있으라는데 주사실이 어딘데요?</td>\n",
       "      <td>침을 맞는 곳이라 이름이 주사실입니다. 3층으로 올라가시면 됩니다.</td>\n",
       "      <td>29.대기실 및 진료실 위치 안내</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  \\\n",
       "0                      너무 목이 마른데요, 혹시 정수기 같은 건 없나요?   \n",
       "1                           교정기가 떨어진 것 같아서 붙이러 왔어요.   \n",
       "2  앞으로 얼마나 나아지는지 보고 아프면 오라고 하네요. 제가 다음에 예약하고 와도 되죠?   \n",
       "3                   이것도 수납용 키오스크인가요? 대기 줄이 너무 길어서요.   \n",
       "4                        주사실 안에 가서 있으라는데 주사실이 어딘데요?   \n",
       "\n",
       "                                           answer          category02  \n",
       "0                   정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.  29.대기실 및 진료실 위치 안내  \n",
       "1           접수 먼저 부탁드립니다. 카운터에서 성함을 입력해 주시길 바랍니다.         27.진료 접수 안내  \n",
       "2  예약하실 때 지난 번 진료 기록이 있다고 말씀해 주시길 부탁 드립니다. 감사합니다.        33.다음 진료실 예약  \n",
       "3      이곳에서도 수납 진행 가능합니다. 홈버튼을 누른 후 수납 버튼을 누르십시오.         31.수납 방법 안내  \n",
       "4           침을 맞는 곳이라 이름이 주사실입니다. 3층으로 올라가시면 됩니다.  29.대기실 및 진료실 위치 안내  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('file/health_result.csv')\n",
    "\n",
    "# 질문 리스트\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# fine-tuning된 모델과 토크나이저 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsek\\AppData\\Local\\Temp\\ipykernel_924\\1734250886.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  question_embeddings = torch.load('new_question_embeddings.pth')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# numpy의 _reconstruct 함수를 허용 목록에 추가\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])\n",
    "\n",
    "# 신뢰할 수 있는 데이터 파일을 로드\n",
    "question_embeddings = torch.load('new_question_embeddings.pth')\n",
    "\n",
    "# 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "def get_embedding(input_question, tokenizer, model):\n",
    "    # 입력 문장을 토크나이즈\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # hidden states를 포함하도록 설정\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # 마지막 hidden state에서 [CLS] 토큰의 임베딩을 가져옴\n",
    "        cls_embedding = outputs.hidden_states[-1][:, 0, :]  # [CLS] 토큰의 임베딩\n",
    "        \n",
    "    return cls_embedding.squeeze().numpy()  # numpy 배열로 반환\n",
    "\n",
    "\n",
    "\n",
    "# 코사인 유사도를 계산하여 가장 유사한 답변을 찾는 함수\n",
    "def find_most_similar_answer_cosine(input_question, question_embeddings, answers, tokenizer, model):\n",
    "    # 입력 질문 임베딩 생성\n",
    "    input_embedding = get_embedding(input_question, tokenizer, model)\n",
    "\n",
    "    max_similarity = -1\n",
    "    best_answer = None\n",
    "    \n",
    "    # 각 질문 임베딩과 유사도 비교\n",
    "    for i, question_embedding in enumerate(question_embeddings):\n",
    "        # question_embedding을 텐서로 변환하고 차원 맞추기\n",
    "        question_embedding_tensor = torch.tensor(question_embedding).unsqueeze(0)  # (1, 768)\n",
    "        \n",
    "        # input_embedding도 텐서로 변환하고 차원 맞추기\n",
    "        input_embedding_tensor = torch.tensor(input_embedding).unsqueeze(0)  # (1, 768)\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        similarity = F.cosine_similarity(input_embedding_tensor, question_embedding_tensor).item()\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = answers[i]\n",
    "\n",
    "    return best_answer, max_similarity  # 유사도 반환 추가\n",
    "\n",
    "# 챗봇 응답 함수\n",
    "def chatbot_response(input_question, tokenizer, model, question_embeddings, answers):\n",
    "    # 1차 필터링: 분류 모델로 레이블 예측\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 2차 필터링: 같은 카테고리 내에서 코사인 유사도 계산\n",
    "    # 같은 레이블의 질문들과 임베딩 필터링\n",
    "    filtered_df = df[df['label'] == predicted_label]\n",
    "    filtered_indices = filtered_df.index.tolist()\n",
    "\n",
    "    # 필터링된 질문에 해당하는 미리 계산된 임베딩과 답변 가져오기\n",
    "    filtered_question_embeddings = [question_embeddings[i] for i in filtered_indices]\n",
    "    filtered_answers = [answers[i] for i in filtered_indices]\n",
    "\n",
    "    # 코사인 유사도를 통해 가장 유사한 답변 찾기\n",
    "    best_answer, cosine_similarity = find_most_similar_answer_cosine(input_question, filtered_question_embeddings, filtered_answers, tokenizer, model)\n",
    "    \n",
    "    return best_answer, cosine_similarity, predicted_label  # 세 가지 값 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 0\n",
      "최고 유사도 답변: 제가 안내해 드리겠습니다. 저를 따라 이동해 주시기 바랍니다.\n",
      "코사인 유사도: 0.9999990463256836\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"정수기는 위치가 어디죠?\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 0\n",
      "최고 유사도 답변: 정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.\n",
      "코사인 유사도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"너무 목이 마른데요, 혹시 정수기 같은 건 없나요?\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
