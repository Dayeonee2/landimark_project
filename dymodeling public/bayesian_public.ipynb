{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>category02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여기 서명란에 펜이나 연필로 사인해도 되는 거 아니에요?</td>\n",
       "      <td>확인 결과 인감 외 사인도 동일 서명으로 처리됩니다.</td>\n",
       "      <td>17.민원 신청서 용어 질문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이런 전기 요금 할인처럼 비슷한 서비스 같은 것이 또 있나요?</td>\n",
       "      <td>네 소득기준과 세대원 특정 기준에 모두 충족하는 세대에게 에너지 바우처를 지원해 줍니다.</td>\n",
       "      <td>18.관내 복지 지원금 정보 질문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여기 소포 보낼 때 한 번에 결제하고 그런 서비스는 지원 안 하나요?</td>\n",
       "      <td>죄송합니다. 선불로 처리될 수밖에 없는 점 양해 부탁드립니다.</td>\n",
       "      <td>18.관내 복지 지원금 정보 질문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이런데 로봇이 있어? 신기하네 사업 지원금 관련 담당자는 어디 계실까요?</td>\n",
       "      <td>담당자분 성함 알려주시면 확인 후 안내 도와드리겠습니다.</td>\n",
       "      <td>13.입장 및 민원서비스 이용 안내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서류 가지고 왔어요. 여기에 제출하면 되죠?</td>\n",
       "      <td>성적장학금의 경우 재학 증명서와 성적 증명서가 필요합니다.</td>\n",
       "      <td>15.준비서류 확인</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0           여기 서명란에 펜이나 연필로 사인해도 되는 거 아니에요?   \n",
       "1        이런 전기 요금 할인처럼 비슷한 서비스 같은 것이 또 있나요?   \n",
       "2    여기 소포 보낼 때 한 번에 결제하고 그런 서비스는 지원 안 하나요?   \n",
       "3  이런데 로봇이 있어? 신기하네 사업 지원금 관련 담당자는 어디 계실까요?   \n",
       "4                  서류 가지고 왔어요. 여기에 제출하면 되죠?   \n",
       "\n",
       "                                              answer           category02  \n",
       "0                      확인 결과 인감 외 사인도 동일 서명으로 처리됩니다.      17.민원 신청서 용어 질문  \n",
       "1  네 소득기준과 세대원 특정 기준에 모두 충족하는 세대에게 에너지 바우처를 지원해 줍니다.   18.관내 복지 지원금 정보 질문  \n",
       "2                 죄송합니다. 선불로 처리될 수밖에 없는 점 양해 부탁드립니다.   18.관내 복지 지원금 정보 질문  \n",
       "3                    담당자분 성함 알려주시면 확인 후 안내 도와드리겠습니다.  13.입장 및 민원서비스 이용 안내  \n",
       "4                   성적장학금의 경우 재학 증명서와 성적 증명서가 필요합니다.           15.준비서류 확인  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('public_result.csv')\n",
    "\n",
    "# 질문 리스트\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# fine-tuning된 모델과 토크나이저 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsek\\AppData\\Local\\Temp\\ipykernel_924\\1734250886.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  question_embeddings = torch.load('new_question_embeddings.pth')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# numpy의 _reconstruct 함수를 허용 목록에 추가\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])\n",
    "\n",
    "# 신뢰할 수 있는 데이터 파일을 로드\n",
    "question_embeddings = torch.load('embeddings/new_question_embeddings.pth')\n",
    "\n",
    "# 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "def get_embedding(input_question, tokenizer, model):\n",
    "    # 입력 문장을 토크나이즈\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # hidden states를 포함하도록 설정\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # 마지막 hidden state에서 [CLS] 토큰의 임베딩을 가져옴\n",
    "        cls_embedding = outputs.hidden_states[-1][:, 0, :]  # [CLS] 토큰의 임베딩\n",
    "        \n",
    "    return cls_embedding.squeeze().numpy()  # numpy 배열로 반환\n",
    "\n",
    "\n",
    "\n",
    "# 코사인 유사도를 계산하여 가장 유사한 답변을 찾는 함수\n",
    "def find_most_similar_answer_cosine(input_question, question_embeddings, answers, tokenizer, model):\n",
    "    # 입력 질문 임베딩 생성\n",
    "    input_embedding = get_embedding(input_question, tokenizer, model)\n",
    "\n",
    "    max_similarity = -1\n",
    "    best_answer = None\n",
    "    \n",
    "    # 각 질문 임베딩과 유사도 비교\n",
    "    for i, question_embedding in enumerate(question_embeddings):\n",
    "        # question_embedding을 텐서로 변환하고 차원 맞추기\n",
    "        question_embedding_tensor = torch.tensor(question_embedding).unsqueeze(0)  # (1, 768)\n",
    "        \n",
    "        # input_embedding도 텐서로 변환하고 차원 맞추기\n",
    "        input_embedding_tensor = torch.tensor(input_embedding).unsqueeze(0)  # (1, 768)\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        similarity = F.cosine_similarity(input_embedding_tensor, question_embedding_tensor).item()\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = answers[i]\n",
    "\n",
    "    return best_answer, max_similarity  # 유사도 반환 추가\n",
    "\n",
    "# 챗봇 응답 함수\n",
    "def chatbot_response(input_question, tokenizer, model, question_embeddings, answers):\n",
    "    # 1차 필터링: 분류 모델로 레이블 예측\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 2차 필터링: 같은 카테고리 내에서 코사인 유사도 계산\n",
    "    # 같은 레이블의 질문들과 임베딩 필터링\n",
    "    filtered_df = df[df['label'] == predicted_label]\n",
    "    filtered_indices = filtered_df.index.tolist()\n",
    "\n",
    "    # 필터링된 질문에 해당하는 미리 계산된 임베딩과 답변 가져오기\n",
    "    filtered_question_embeddings = [question_embeddings[i] for i in filtered_indices]\n",
    "    filtered_answers = [answers[i] for i in filtered_indices]\n",
    "\n",
    "    # 코사인 유사도를 통해 가장 유사한 답변 찾기\n",
    "    best_answer, cosine_similarity = find_most_similar_answer_cosine(input_question, filtered_question_embeddings, filtered_answers, tokenizer, model)\n",
    "    \n",
    "    return best_answer, cosine_similarity, predicted_label  # 세 가지 값 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 0\n",
      "최고 유사도 답변: 제가 안내해 드리겠습니다. 저를 따라 이동해 주시기 바랍니다.\n",
      "코사인 유사도: 0.9999990463256836\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"정수기는 위치가 어디죠?\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 0\n",
      "최고 유사도 답변: 정수기는 진료 대기실 앞 쪽에 있습니다. 감사합니다.\n",
      "코사인 유사도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"너무 목이 마른데요, 혹시 정수기 같은 건 없나요?\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(input_question, tokenizer, model, question_embeddings, answers)\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
