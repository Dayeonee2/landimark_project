{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>category02</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여기 서명란에 펜이나 연필로 사인해도 되는 거 아니에요?</td>\n",
       "      <td>확인 결과 인감 외 사인도 동일 서명으로 처리됩니다.</td>\n",
       "      <td>민원 신청서 용어 질문</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이런 전기 요금 할인처럼 비슷한 서비스 같은 것이 또 있나요?</td>\n",
       "      <td>네 소득기준과 세대원 특정 기준에 모두 충족하는 세대에게 에너지 바우처를 지원해 줍니다.</td>\n",
       "      <td>관내 복지 지원금 정보 질문</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여기 소포 보낼 때 한 번에 결제하고 그런 서비스는 지원 안 하나요?</td>\n",
       "      <td>죄송합니다. 선불로 처리될 수밖에 없는 점 양해 부탁드립니다.</td>\n",
       "      <td>관내 복지 지원금 정보 질문</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이런데 로봇이 있어? 신기하네 사업 지원금 관련 담당자는 어디 계실까요?</td>\n",
       "      <td>담당자분 성함 알려주시면 확인 후 안내 도와드리겠습니다.</td>\n",
       "      <td>입장 및 민원서비스 이용 안내</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서류 가지고 왔어요. 여기에 제출하면 되죠?</td>\n",
       "      <td>성적장학금의 경우 재학 증명서와 성적 증명서가 필요합니다.</td>\n",
       "      <td>준비서류 확인</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0           여기 서명란에 펜이나 연필로 사인해도 되는 거 아니에요?   \n",
       "1        이런 전기 요금 할인처럼 비슷한 서비스 같은 것이 또 있나요?   \n",
       "2    여기 소포 보낼 때 한 번에 결제하고 그런 서비스는 지원 안 하나요?   \n",
       "3  이런데 로봇이 있어? 신기하네 사업 지원금 관련 담당자는 어디 계실까요?   \n",
       "4                  서류 가지고 왔어요. 여기에 제출하면 되죠?   \n",
       "\n",
       "                                              answer        category02  label  \n",
       "0                      확인 결과 인감 외 사인도 동일 서명으로 처리됩니다.      민원 신청서 용어 질문      0  \n",
       "1  네 소득기준과 세대원 특정 기준에 모두 충족하는 세대에게 에너지 바우처를 지원해 줍니다.   관내 복지 지원금 정보 질문      1  \n",
       "2                 죄송합니다. 선불로 처리될 수밖에 없는 점 양해 부탁드립니다.   관내 복지 지원금 정보 질문      1  \n",
       "3                    담당자분 성함 알려주시면 확인 후 안내 도와드리겠습니다.  입장 및 민원서비스 이용 안내      2  \n",
       "4                   성적장학금의 경우 재학 증명서와 성적 증명서가 필요합니다.           준비서류 확인      3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('public_result_label.csv')\n",
    "\n",
    "# 질문 리스트\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Temp\\ipykernel_12132\\3226958015.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model/public_model_weights.pth', map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "# 모델 구조를 정의한 코드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcBERT-base\", num_labels=6)\n",
    "\n",
    "# 모델 가중치를 CPU로 로드\n",
    "model.load_state_dict(torch.load('model/public_model_weights.pth', map_location=torch.device('cpu')))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Temp\\ipykernel_12132\\594036569.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  question_embeddings = torch.load('embeddings/public_train_question_embeddings.pth')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# numpy의 _reconstruct 함수를 허용 목록에 추가\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])\n",
    "\n",
    "# 데이터프레임과 디바이스 설정\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# 신뢰할 수 있는 데이터 파일을 로드하고 GPU로 이동\n",
    "question_embeddings = torch.load('embeddings/public_train_question_embeddings.pth')\n",
    "question_embeddings = [torch.tensor(embedding).to(device) for embedding in question_embeddings]  # 모든 임베딩을 GPU로 이동\n",
    "\n",
    "# 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def get_embedding(input_question, tokenizer, model, device):\n",
    "    # 입력 문장을 토크나이즈하고 GPU/CPU로 이동\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # hidden states를 포함하도록 설정\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # 마지막 hidden state에서 [CLS] 토큰의 임베딩을 가져옴\n",
    "        cls_embedding = outputs.hidden_states[-1][:, 0, :]  # [CLS] 토큰의 임베딩\n",
    "    \n",
    "    return cls_embedding.squeeze().to(device)  # 텐서를 GPU로 반환\n",
    "\n",
    "# 코사인 유사도를 계산하여 가장 유사한 답변을 찾는 함수\n",
    "def find_most_similar_answer_cosine(input_question, question_embeddings, answers, tokenizer, model, device):\n",
    "    # 입력 질문 임베딩 생성\n",
    "    input_embedding = get_embedding(input_question, tokenizer, model, device)\n",
    "\n",
    "    max_similarity = -1\n",
    "    best_answer = None\n",
    "    \n",
    "    # 각 질문 임베딩과 유사도 비교\n",
    "    for i, question_embedding in enumerate(question_embeddings):\n",
    "        # 코사인 유사도 계산\n",
    "        similarity = F.cosine_similarity(input_embedding.unsqueeze(0), question_embedding.unsqueeze(0)).item()\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = answers[i]\n",
    "\n",
    "    return best_answer, max_similarity\n",
    "\n",
    "# 챗봇 응답 함수\n",
    "def chatbot_response(input_question, tokenizer, model, question_embeddings, answers, df, device):\n",
    "    # 1차 필터링: 분류 모델로 레이블 예측\n",
    "    inputs = tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 2차 필터링: 같은 카테고리 내에서 코사인 유사도 계산\n",
    "    # 같은 레이블의 질문들과 임베딩 필터링\n",
    "    filtered_df = df[df['label'] == predicted_label]\n",
    "    filtered_indices = filtered_df.index.tolist()\n",
    "\n",
    "    # 필터링된 질문에 해당하는 미리 계산된 임베딩과 답변 가져오기\n",
    "    filtered_question_embeddings = [question_embeddings[i] for i in filtered_indices]\n",
    "    filtered_answers = [answers[i] for i in filtered_indices]\n",
    "\n",
    "    # 코사인 유사도를 통해 가장 유사한 답변 찾기\n",
    "    best_answer, cosine_similarity = find_most_similar_answer_cosine(input_question, filtered_question_embeddings, filtered_answers, tokenizer, model, device)\n",
    "    \n",
    "    return best_answer, cosine_similarity, predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 레이블: 4\n",
      "최고 유사도 답변: 말씀하신 질문에 대한 답변으로, 상담 문의는 능력 개발 운영부입니다.\n",
      "코사인 유사도: 0.8322391510009766\n"
     ]
    }
   ],
   "source": [
    "# 예시 질문\n",
    "input_question = \"서류 제출은 어디에 해요?\"\n",
    "\n",
    "# 챗봇 응답 호출\n",
    "best_answer, cosine_similarity, predicted_label = chatbot_response(\n",
    "    input_question, tokenizer, model, question_embeddings, answers, df, device\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "print(\"예측된 레이블:\", predicted_label)\n",
    "print(\"최고 유사도 답변:\", best_answer)\n",
    "print(\"코사인 유사도:\", cosine_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
